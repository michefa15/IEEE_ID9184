{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dRMrRNlq6ue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a90e0454-0369-4cb1-934d-565d2a7356d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting workalendar\n",
            "  Downloading workalendar-17.0.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from workalendar) (2.8.2)\n",
            "Collecting lunardate (from workalendar)\n",
            "  Downloading lunardate-0.2.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting convertdate (from workalendar)\n",
            "  Downloading convertdate-2.4.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting pyluach (from workalendar)\n",
            "  Downloading pyluach-2.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting pymeeus<=1,>=0.3.13 (from convertdate->workalendar)\n",
            "  Downloading PyMeeus-0.5.12.tar.gz (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->workalendar) (1.16.0)\n",
            "Downloading workalendar-17.0.0-py3-none-any.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading convertdate-2.4.0-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.9/47.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lunardate-0.2.2-py3-none-any.whl (18 kB)\n",
            "Downloading pyluach-2.2.0-py3-none-any.whl (25 kB)\n",
            "Building wheels for collected packages: pymeeus\n",
            "  Building wheel for pymeeus (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pymeeus: filename=PyMeeus-0.5.12-py3-none-any.whl size=732003 sha256=447f0ffb76ee5f920b7bc4ef48bb633d791454541fa196b23e39caf27e51b084\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/67/78/aa2e8d108639dd23a5e9e72a4fc88bb44f5541894382712f48\n",
            "Successfully built pymeeus\n",
            "Installing collected packages: pymeeus, lunardate, pyluach, convertdate, workalendar\n",
            "Successfully installed convertdate-2.4.0 lunardate-0.2.2 pyluach-2.2.0 pymeeus-0.5.12 workalendar-17.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install workalendar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "fyaesUaWrqUG",
        "outputId": "cb2a23b7-9802-4ac3-d50d-fdc7b5ef9c7c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-5a5a08323c97>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#from workalendar.america import Brazil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "# For sending GET requests from the API\n",
        "import requests\n",
        "# For saving access tokens and for file management when creating and adding to the dataset\n",
        "import os\n",
        "# For dealing with json responses we receive from the API\n",
        "import json\n",
        "# For displaying the data after\n",
        "import pandas as pd\n",
        "# For saving the response data in CSV format\n",
        "import csv\n",
        "# For parsing the dates received from twitter in readable formats\n",
        "import datetime\n",
        "import dateutil.parser\n",
        "import unicodedata\n",
        "#To add wait time between requests\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import datetime as dt\n",
        "from datetime import datetime\n",
        "\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#from workalendar.america import Brazil\n",
        "#calendar = Brazil()\n",
        "\n",
        "savepath = '/content/drive/MyDrive/DEV/Python/Datasets/TCC/TW-BKP/'\n",
        "\n",
        "def get_UID():\n",
        "  curdt = dt.datetime.now().astimezone(dt.timezone(dt.timedelta(hours=-3)))\n",
        "  return curdt.strftime('%d%m%Y%H%M%S')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puoUbSmNrray"
      },
      "outputs": [],
      "source": [
        "os.environ['TOKEN'] = 'AAAAAAAAAAAAAAAAAAAAAFWmVwEAAAAA2j3NAasSkAcTzqI57kJ4qMd4J7I%3DuPjd93QYDfK4vdKslDBD1L6hPKdvds8Kh568oaqkjHx77gc0Br'\n",
        "\n",
        "def auth():\n",
        "    return os.getenv('TOKEN')\n",
        "\n",
        "def create_headers(bearer_token):\n",
        "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
        "    return headers\n",
        "\n",
        "def create_url(keyword, start_date, end_date, max_results = 10):\n",
        "\n",
        "    search_url = \"https://api.twitter.com/2/tweets/search/all\"\n",
        "\n",
        "    # Change to the endpoint you want to collect data from\n",
        "\n",
        "    # change params based on the endpoint you are using\n",
        "    #query_params = {'query': keyword,\n",
        "    #                'start_time': start_date,\n",
        "    #                'end_time': end_date,\n",
        "    #                'max_results': max_results,\n",
        "    #                'expansions': 'author_id,in_reply_to_user_id,geo.place_id',\n",
        "    #                'tweet.fields': 'id,text,author_id,in_reply_to_user_id,geo,conversation_id,created_at,lang,public_metrics,referenced_tweets,reply_settings,source',\n",
        "    #                'user.fields': 'id,name,username,created_at,description,public_metrics,verified',\n",
        "    #                'place.fields': 'full_name,id,country,country_code,geo,name,place_type',\n",
        "    #                'next_token': {}}\n",
        "\n",
        "    query_params = {'query': keyword,\n",
        "                    'start_time': start_date,\n",
        "                    'end_time': end_date,\n",
        "                    'max_results': max_results,\n",
        "    #               'expansions': 'author_id,in_reply_to_user_id,geo.place_id',\n",
        "                    'tweet.fields': 'text,created_at', #'id,text,author_id,in_reply_to_user_id,geo,conversation_id,created_at,lang,public_metrics,referenced_tweets,reply_settings,source',\n",
        "    #               'user.fields': 'id,name,username,created_at,description,public_metrics,verified',\n",
        "    #               'place.fields': 'full_name,id,country,country_code,geo,name,place_type',\n",
        "    #               'next_token': {}\n",
        "                    }\n",
        "\n",
        "    return (search_url, query_params)\n",
        "\n",
        "def connect_to_endpoint(url, headers, params, next_token = None):\n",
        "    params['next_token'] = next_token   #params object received from create_url function\n",
        "    response = requests.request(\"GET\", url, headers = headers, params = params)\n",
        "    print(\"Endpoint Response Code: \" + str(response.status_code))\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(response.status_code, response.text)\n",
        "    return response.json()\n",
        "\n",
        "bearer_token = auth()\n",
        "headers = create_headers(bearer_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOI-k5x0pczT"
      },
      "source": [
        "# TEST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlWF7snKtccq"
      },
      "outputs": [],
      "source": [
        "#Inputs for the request\n",
        "\n",
        "keyword = \"from:Ambev -is:reply lang:pt\"\n",
        "start_time = \"2019-01-01T00:00:00.000Z\"\n",
        "end_time = \"2020-01-01T00:00:00.000Z\"\n",
        "user_fields_username = \"\"\n",
        "max_results = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jpAilyXtglU",
        "outputId": "822dd909-fc30-4e6f-f2d2-44122a4db976"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Endpoint Response Code: 200\n"
          ]
        }
      ],
      "source": [
        "url = create_url(keyword, start_time,end_time, max_results)\n",
        "json_response = connect_to_endpoint(url[0], headers, url[1])\n",
        "#print(json.dumps(json_response, indent=4, sort_keys=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVzkHpQc6dK1"
      },
      "outputs": [],
      "source": [
        "tw_data = json_response['data']\n",
        "\n",
        "tw_dates = []\n",
        "tw_texts = []\n",
        "\n",
        "print(tw_data[2])\n",
        "\n",
        "for i in range(len(tw_data)):\n",
        "  print(json_response['data'][i]['created_at'].split('T')[0]+\" | \"+json_response['data'][i]['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtaLhEyLpg4d"
      },
      "source": [
        "# CODE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXl0V9BUsV3t"
      },
      "outputs": [],
      "source": [
        "def get_tweets(date_start, date_end, filename, query='', userlist='none', interval='3M'):\n",
        "  _tweets = []\n",
        "\n",
        "  keyword = ''\n",
        "\n",
        "  if userlist == 'none':\n",
        "    keyword = \"(\"+query+\") lang:pt -is:reply -holidays\"\n",
        "  else:\n",
        "    if query != '':\n",
        "      query = \"(\"+query+\") \"\n",
        "\n",
        "    for username in userlist:\n",
        "      keyword += query+\"from:\"+username+\" \"\n",
        "    keyword += \"lang:pt -is:reply -holidays\"\n",
        "  max_results = 100\n",
        "\n",
        "  print(keyword)\n",
        "  pass\n",
        "  datelist = pd.date_range(start=date_start, end=date_end, freq=interval).to_list()\n",
        "\n",
        "  dto = datetime.strptime(date_end, '%Y-%m-%d')\n",
        "  datelist.append(dto)\n",
        "\n",
        "  prevdate = date_start\n",
        "  print(datelist)\n",
        "\n",
        "  # begin for\n",
        "  for date_item in datelist:\n",
        "    curdate = str(date_item.date())\n",
        "\n",
        "    start_time = prevdate+\"T00:00:00.000Z\"\n",
        "    end_time = curdate+\"T00:00:00.000Z\"\n",
        "\n",
        "    url = create_url(keyword, start_time,end_time, max_results)\n",
        "    json_response = connect_to_endpoint(url[0], headers, url[1])\n",
        "    time.sleep(60)\n",
        "\n",
        "    print(json_response)\n",
        "\n",
        "    tw_data = \"\"\n",
        "    try:\n",
        "      tw_data = json_response['data']\n",
        "      # begin for\n",
        "      for i in range(len(tw_data)):\n",
        "        cdate = tw_data[i]['created_at'].split('T')[0]\n",
        "        ctext = tw_data[i]['text']\n",
        "\n",
        "        _tweet = {\n",
        "            'date':cdate,\n",
        "            'text':ctext\n",
        "        }\n",
        "        _tweets.append(_tweet)\n",
        "        # end for\n",
        "    except:\n",
        "      tw_data = json_response['meta']\n",
        "\n",
        "    prevdate = curdate\n",
        "  # end for\n",
        "\n",
        "  df_tw = pd.DataFrame(_tweets)\n",
        "  df_tw = df_tw.sort_values(by=['date'])\n",
        "\n",
        "  ffname = \"raw_tw_\"+filename+\"_\"+date_start+\"_\"+date_end+\".csv\"\n",
        "  df_tw.to_csv(savepath+ffname, sep=',', index=False)\n",
        "\n",
        "  return df_tw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTwdxVG6yfH8"
      },
      "outputs": [],
      "source": [
        "emp = 'petrobras'\n",
        "#emp = 'valenobrasil'\n",
        "#emp = 'Bradesco'\n",
        "#emp = 'Ambev'\n",
        "#emp = 'itau'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajgrAjROOJkp"
      },
      "outputs": [],
      "source": [
        "tw_data = get_tweets('2019-01-01', '2021-01-01','ABEV3', query='ABEV3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9hhiyptvzWH"
      },
      "outputs": [],
      "source": [
        "tw_data = get_tweets('2006-04-01', '2022-01-01','petrobras', userlist=['petrobras'], interval='3M')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFmteCGxyWz5"
      },
      "outputs": [],
      "source": [
        "tw_data = get_tweets('2020-01-01', '2021-01-01','petrobras', userlist=['petrobras'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stock_list = [['PETR4', 'petrobras OR PETR4'],\n",
        "              ['VALE3', '\"vale do rio docê\" OR \"VALE3\" OR \"minério\"'],\n",
        "              ['ABEV3', 'ambev OR ABEV3'],\n",
        "              ['ITUB4', 'itaú OR ITUB4'],\n",
        "              ['BBDC4', 'bradesco OR BBDC4']]\n",
        "\n",
        "journals = ['InvestingBrasil',\n",
        "            'leiamoneytimes',\n",
        "            'infomoney',\n",
        "            'valoreconomico']\n",
        "\n"
      ],
      "metadata": {
        "id": "iCMXtIiI2mx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-50XJwbjQxd"
      },
      "outputs": [],
      "source": [
        "sfstart = '2008-01-01'\n",
        "sfend = '2022-09-20'\n",
        "\n",
        "stock_idx = 1\n",
        "\n",
        "savepath += get_UID()+\"/\"\n",
        "\n",
        "if not os.path.exists(savepath):\n",
        "    os.makedirs(savepath)\n",
        "\n",
        "for journal in journals:\n",
        "  tw_data = get_tweets(sfstart, sfend, stock_list[stock_idx][0]+'_'+journal, userlist=[journal], query=stock_list[stock_idx][1])\n",
        "\n",
        "#InvestingBrasil\n",
        "#tw_data = get_tweets(sfstart, sfend, stock_list[stock_idx][0]+'_InvestingBrasil', userlist=['InvestingBrasil'], query=stock_list[stock_idx][1])\n",
        "\n",
        "#leiamoneytimes\n",
        "#tw_data = get_tweets(sfstart, sfend, stock_list[stock_idx][0]+'_leiamoneytimes', userlist=['leiamoneytimes'], query=stock_list[stock_idx][1])\n",
        "\n",
        "#infomoney\n",
        "#tw_data = get_tweets(sfstart, sfend, stock_list[stock_idx][0]+'_infomoney', userlist=['infomoney'], query=stock_list[stock_idx][1])\n",
        "\n",
        "#valoreconomico\n",
        "#tw_data = get_tweets(sfstart, sfend, stock_list[stock_idx][0]+'_valoreconomico', userlist=['valoreconomico'], query=stock_list[stock_idx][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0UBwLmlqKpC"
      },
      "outputs": [],
      "source": [
        "tw_data = get_tweets('2008-01-01', '2022-08-31','PETR4', query='PETR4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61UqPLzl-52S"
      },
      "outputs": [],
      "source": [
        "datelist2 = pd.date_range(start='2021-01-01', end='2022-01-01', freq='3M').to_list()\n",
        "\n",
        "date_str = '2022-01-01'\n",
        "dto = datetime.strptime(date_str, '%Y-%m-%d')\n",
        "\n",
        "datelist2.append(dto)\n",
        "\n",
        "for date_item in datelist2:\n",
        "  print(date_item.date())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ukY5P38-HUA"
      },
      "source": [
        "# MERGE DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHv5A8FF-MyL",
        "outputId": "a7b438eb-6c28-42b8-9411-f1260470867b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           date                                               text\n",
            "4459 2009-04-28  produção de minério de ferro da vale cai 37% h...\n",
            "4460 2009-05-18  preço de minério sai nas próximas semanas http...\n",
            "4461 2009-05-26  rio tinto aceita desconto de 33% no minério ht...\n",
            "4462 2009-06-10  vale acerta preço de minério de ferro com nipp...\n",
            "4463 2009-07-17  vale fecha desconto no preço do minério para i...\n"
          ]
        }
      ],
      "source": [
        "curstock = 1\n",
        "\n",
        "merge_files = ['raw_tw_'+stock_list[curstock][0]+'_InvestingBrasil_2008-01-01_2022-09-20.csv',\n",
        "               'raw_tw_'+stock_list[curstock][0]+'_infomoney_2008-01-01_2022-09-20.csv',\n",
        "               'raw_tw_'+stock_list[curstock][0]+'_leiamoneytimes_2008-01-01_2022-09-20.csv',\n",
        "               'raw_tw_'+stock_list[curstock][0]+'_valoreconomico_2008-01-01_2022-09-20.csv']\n",
        "\n",
        "\n",
        "\n",
        "df_files = []\n",
        "for item in merge_files:\n",
        "  df_files.append(pd.read_csv(item))\n",
        "# -----------\n",
        "\n",
        "df_merge = pd.concat(df_files, ignore_index=True)\n",
        "df_merge = df_merge.apply(lambda x: x.astype(str).str.lower()).drop_duplicates(subset=['text'], keep=False)\n",
        "df_merge['date'] = pd.to_datetime(df_merge['date'])\n",
        "df_merge = df_merge.sort_values(by='date')\n",
        "\n",
        "df_merge.to_csv('tw_'+stock_list[curstock][0]+'.csv', sep=',', index=False)\n",
        "\n",
        "\n",
        "\n",
        "print(df_merge.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ib82wwNfAfwf",
        "outputId": "7904567b-35ad-4f5c-9498-596e53f40091"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1931\n",
            "4614\n",
            "2274\n",
            "3580\n",
            "12399\n",
            "12214\n"
          ]
        }
      ],
      "source": [
        "for item in df_files:\n",
        "  print(len(item))\n",
        "\n",
        "print(len(df_merge))\n",
        "\n",
        "#df_merge = df_merge.drop_duplicates(keep=False)\n",
        "#df_merge = df_merge.drop_duplicates(subset=[\"text\"], keep=False)\n",
        "\n",
        "df_merge = df_merge.apply(lambda x: x.astype(str).str.lower()).drop_duplicates(subset=['text'], keep=False)\n",
        "\n",
        "\n",
        "print(len(df_merge))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MMy2XK8CBKEp",
        "outputId": "c9e3cea4-08b5-421a-deac-9135c10639c5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3d5b140c-6e68-4b57-ad18-0eceaa1b72fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1926</th>\n",
              "      <td>2022-09-12</td>\n",
              "      <td>#Petrobras reduz preço do gás de cozinha em 4,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1927</th>\n",
              "      <td>2022-09-16</td>\n",
              "      <td>CEO da #Petrobras é diagnosticado com câncer -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1928</th>\n",
              "      <td>2022-09-16</td>\n",
              "      <td>Petrobras capta R$3 bi com emissão de notas co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1929</th>\n",
              "      <td>2022-09-19</td>\n",
              "      <td>Goldman Sachs: Petrobras com margens consolida...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1930</th>\n",
              "      <td>2022-09-19</td>\n",
              "      <td>#Petrobras reduz preço do diesel em 5,78% para...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d5b140c-6e68-4b57-ad18-0eceaa1b72fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3d5b140c-6e68-4b57-ad18-0eceaa1b72fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3d5b140c-6e68-4b57-ad18-0eceaa1b72fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            date                                               text\n",
              "1926  2022-09-12  #Petrobras reduz preço do gás de cozinha em 4,...\n",
              "1927  2022-09-16  CEO da #Petrobras é diagnosticado com câncer -...\n",
              "1928  2022-09-16  Petrobras capta R$3 bi com emissão de notas co...\n",
              "1929  2022-09-19  Goldman Sachs: Petrobras com margens consolida...\n",
              "1930  2022-09-19  #Petrobras reduz preço do diesel em 5,78% para..."
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_files[0].tail()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "mOI-k5x0pczT"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}