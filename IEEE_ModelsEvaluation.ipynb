{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dec1967-b6ad-4561-a470-4240dd4f9409",
   "metadata": {},
   "source": [
    "## 1 - Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "41434563-c26f-4b4c-a301-234c248cad1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "477ff465-94ff-4b87-856e-af33fe87fc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    'PETR4_textuais_numericos.csv',\n",
    "    encoding='utf-8-sig', \n",
    "    index_col='date'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d4a09ef-849e-4f29-994a-9146b7847139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3622, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e38001c-6d2e-45ff-a248-4fd528e5e500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['close', 'compound_gn', 'negative_gn', 'neutral_gn', 'positive_gn',\n",
       "       'compound_tw', 'negative_tw', 'neutral_tw', 'positive_tw', 'open',\n",
       "       'high', 'low', 'volume'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa913626-c769-4f1a-8498-7bbc50376c6c",
   "metadata": {},
   "source": [
    "## 2 - Funções auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a6de7a-3244-4497-bb75-350ef0aa5cd8",
   "metadata": {},
   "source": [
    "### 2.1 Calcular os Indicadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87d7b723-21c2-49f6-84b9-ee2bec63c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calcular_mms(df, periodo):\n",
    "    \"\"\"\n",
    "    Calcula a Média Móvel Simples (MMS).\n",
    "    \n",
    "    Args:\n",
    "        precos (list ou pd.Series): Série de preços.\n",
    "        periodo (int): Período da média móvel.\n",
    "    \n",
    "    Returns:\n",
    "        pd.Series: Média Móvel Simples.\n",
    "    \"\"\"\n",
    "    df[f'mms_{periodo}'] = df['close'].rolling(window=periodo).mean()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def calcular_mme(df, periodo):\n",
    "    \"\"\"\n",
    "    Calcula a Média Móvel Exponencial (MME).\n",
    "    \n",
    "    Args:\n",
    "        precos (list ou pd.Series): Série de preços.\n",
    "        periodo (int): Período da média móvel.\n",
    "    \n",
    "    Returns:\n",
    "        pd.Series: Média Móvel Exponencial.\n",
    "    \"\"\"\n",
    "    df[f'mme_{periodo}'] = df['close'].ewm(span=periodo, adjust=False).mean()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def calcular_ifr(df, periodo=14):\n",
    "    \"\"\"\n",
    "    Calcula o Índice de Força Relativa (IFR ou RSI - Relative Strength Index).\n",
    "    \n",
    "    Args:\n",
    "        precos (list ou pd.Series): Série de preços.\n",
    "        periodo (int): Período do IFR.\n",
    "    \n",
    "    Returns:\n",
    "        pd.Series: Valores do IFR.\n",
    "    \"\"\"\n",
    "    precos = df['close']\n",
    "    variacao = precos.diff(1)\n",
    "    \n",
    "    ganho = variacao.where(variacao > 0, 0)\n",
    "    perda = -variacao.where(variacao < 0, 0)\n",
    "    \n",
    "    media_ganho = ganho.rolling(window=periodo).mean()\n",
    "    media_perda = perda.rolling(window=periodo).mean()\n",
    "    \n",
    "    rs = media_ganho / media_perda\n",
    "    ifr = 100 - (100 / (1 + rs))\n",
    "    df[f'ifr_{periodo}'] = ifr\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698aeb7c-c892-4baa-8881-e1dfb716529f",
   "metadata": {},
   "source": [
    "### 2.2 Carregar Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b1361d0c-1de2-4495-9757-57374a6124a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de função para obter os dados das ações\n",
    "def get_stock_data(stock):\n",
    "    \"\"\"\n",
    "    Função para carregar os dados uma ação.\n",
    "\n",
    "    Parâmetros:\n",
    "        stock (str): Nome da ação.\n",
    "\n",
    "    Retorna:\n",
    "        tuple: DataFrame com os dados da ação e o nome da coluna de destino (target).\n",
    "    \"\"\"\n",
    "    # Carregando\n",
    "    df = pd.read_csv(\n",
    "    f'{stock}_textuais_numericos.csv',\n",
    "    encoding='utf-8-sig', \n",
    "    index_col='date'\n",
    "    )\n",
    "\n",
    "    # Calcular os indicadores técnicos\n",
    "    df = calcular_mms(df, 30)\n",
    "    df = calcular_mms(df, 5)\n",
    "    df = calcular_mme(df, 5)\n",
    "    df = calcular_mme(df, 30)\n",
    "    df = calcular_ifr(df)\n",
    "\n",
    "    # Limpar os dados\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "76ddfae3-333c-4d52-8008-06e91874fa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stocks_data(stocks):\n",
    "    \"\"\"\n",
    "    Carrega os dados das empresas usando a função get_stock_data e armazena-os em um dicionário.\n",
    "\n",
    "    Parâmetros:\n",
    "        stocks (list): Lista de códigos das ações.\n",
    "\n",
    "    Retorna:\n",
    "        dict: Dicionário com os códigos das ações como chave e os dados como valor.\n",
    "    \"\"\"\n",
    "    stock_data_dict = {}\n",
    "    \n",
    "    for stock in stocks:\n",
    "        try:\n",
    "            print(f\"Carregando dados para: {stock}\")\n",
    "            stock_data = get_stock_data(stock)  # Obtém os dados da função\n",
    "            stock_data_dict[stock] = stock_data\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao carregar dados para {stock}: {e}\")\n",
    "    \n",
    "    return stock_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f64d78-214a-4b3d-b507-feb14d27acc9",
   "metadata": {},
   "source": [
    "### 2.3 Combinações dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4d6ab561-8a1e-4b6f-b5c7-e63f1f708387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_combination_data(df, num_combination):\n",
    "    \"\"\"\n",
    "    Combina dados com base em um identificador e retorna o DataFrame combinado e uma descrição.\n",
    "\n",
    "    Parâmetros:\n",
    "        df (pd.DataFrame): DataFrame com os dados originais.\n",
    "        num_combination (int): Número identificador da combinação.\n",
    "\n",
    "    Retorna:\n",
    "        tuple: DataFrame combinado e descrição da combinação.\n",
    "    \"\"\"\n",
    "    # Definindo as combinações\n",
    "    # Stock Data\n",
    "    stock_data = ['open','close','high','low','volume']\n",
    "    # Google News\n",
    "    google_news = ['compound_gn', 'negative_gn', 'neutral_gn', 'positive_gn']\n",
    "    # Twitter\n",
    "    twitter = ['compound_tw', 'negative_tw', 'neutral_tw', 'positive_tw']\n",
    "    # MMS\n",
    "    mms = ['mms_30', 'mms_5']\n",
    "    # MME\n",
    "    mme = ['mme_5', 'mme_30']\n",
    "    # IFR de 14 periodos\n",
    "    ifr = ['ifr_14']\n",
    "    # Valor de fechamento\n",
    "    close = ['close']\n",
    "    \n",
    "    # Mapear combinações para descrição e colunas\n",
    "    combinations = {\n",
    "        1: (\"Stock Data\", stock_data),\n",
    "        2: (\"Stock Data + Google News\", stock_data + google_news),\n",
    "        3: (\"Stock Data + Twitter\", stock_data + twitter),\n",
    "        4: (\"Stock Data + IT (IFR + MMS + MME)\", stock_data + ifr + mms + mme),\n",
    "        5: (\"Google News + Twitter + IFR + MMS\", close + google_news + twitter + ifr + mms),\n",
    "        6: (\"Google News + Twitter + IFR + MME\", close + google_news + twitter + ifr + mme),\n",
    "        7: (\"Google News + Twitter + IFR + MME + MMS\", close + google_news + twitter + ifr + mme + mms),\n",
    "    }\n",
    "\n",
    "    # Verifica se a combinação existe\n",
    "    if num_combination not in combinations:\n",
    "        raise ValueError(f\"Combinação {num_combination} não é válida. Escolha entre 1 e {len(combinations)}.\")\n",
    "\n",
    "    # Recupera descrição e colunas da combinação\n",
    "    description_combination, selected_columns = combinations[num_combination]\n",
    "\n",
    "    # Retorna o DataFrame filtrado e a descrição\n",
    "    return df[selected_columns], description_combination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2a6324-5f7d-4e8a-afd8-f41a103ea2d5",
   "metadata": {},
   "source": [
    "### 2.4 Definição do Alvo - Regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "39e90324-320a-4b75-ba65-7748c179f074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_target(df, target_column='close'):\n",
    "    \"\"\"\n",
    "    Define a coluna de alvo para um modelo de regressão com base no preço de fechamento do próximo dia.\n",
    "    \n",
    "    Parâmetros:\n",
    "        df (pd.DataFrame): DataFrame com os dados.\n",
    "        target_column (str): Nome da coluna que será usada como base para o cálculo do alvo. Default é 'close'.\n",
    "    \n",
    "    Retorna:\n",
    "        pd.DataFrame: DataFrame atualizado com a nova coluna de alvo ('close_next_day') e sem a última linha.\n",
    "    \"\"\"\n",
    "    # Trabalhar com uma cópia explícita do DataFrame para evitar avisos\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Criar a coluna de preço de fechamento do próximo dia\n",
    "    df['close_next_day'] = df[target_column].shift(-1)\n",
    "    \n",
    "    # Remover a última linha, pois não há valor para a previsão do próximo dia\n",
    "    df = df[:-1]\n",
    " \n",
    "    return df, 'close_next_day'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521566a2-2ea4-4ceb-ad65-8d759fa83f8f",
   "metadata": {},
   "source": [
    "### 2.5 Treinamento dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efe901d-2370-4d9f-8186-325c684d3d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm_model(df, target_column, name_model):\n",
    "    \"\"\"\n",
    "    Treina um modelo LSTM em dados de séries temporais e retorna as métricas de desempenho.\n",
    "\n",
    "    Parâmetros:\n",
    "        df (pd.DataFrame): DataFrame com os dados.\n",
    "        target_column (str): Nome da coluna de destino (target).\n",
    "\n",
    "    Retorna:\n",
    "        dict: Dicionário com métricas de desempenho (Loss, MSE, RMSE, MAE, MAPE, Acurácia).\n",
    "    \"\"\"\n",
    "    # Separando as variáveis independentes (X) e dependente (y)\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "\n",
    "    # Dividindo os dados em 80% para treino e 20% para teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    # Escalonando os dados para que os valores estejam entre 0 e 1\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Reshape dos dados para LSTM (adicionar dimensão para timesteps)\n",
    "    X_train_scaled = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "    X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "    # Mapeamento de nomes de modelos para funções\n",
    "    model_mapping = {\n",
    "    'model_1': model_1,\n",
    "    'model_2': model_2,\n",
    "    'model_3': model_3,\n",
    "    'model_linear_simple': model_linear_simple,\n",
    "    }\n",
    "\n",
    "    # Chamando o modelo\n",
    "    if name_model == 'model_3':\n",
    "        model = model_mapping[name_model]((X.shape[1],), learning_rate=0.001)\n",
    "    else:\n",
    "        model = model_mapping[name_model]((X_train_scaled.shape[1], X_train_scaled.shape[2]), learning_rate=0.001)\n",
    "    \n",
    "    # Configurando EarlyStopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Treinando o modelo\n",
    "    history = model.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        #X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test_scaled, y_test),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Prevendo no conjunto de teste\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Calculando métricas adicionais\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(y_test - y_pred))\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "    # Coeficiente de determinação (R²)\n",
    "    ss_total = np.sum((y_test - np.mean(y_test)) ** 2)  # Soma dos quadrados totais\n",
    "    ss_residual = np.sum((y_test - y_pred.flatten()) ** 2)  # Soma dos quadrados residuais\n",
    "    r2 = 1 - (ss_residual / ss_total)\n",
    "\n",
    "    # Acurácia considerando 2% de margem de erro\n",
    "    margin = 0.02\n",
    "    accuracy = accuracy_score(\n",
    "        (np.abs(y_test - y_pred.flatten()) <= margin * y_test).astype(int),\n",
    "        np.ones_like(y_test)\n",
    "    )\n",
    "\n",
    "    # Montando o dicionário de métricas\n",
    "    metrics_dict = {\n",
    "        \"Loss\": history.history['loss'][-1],\n",
    "        \"MSE\": mse,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"MAPE\": mape,\n",
    "        \"R²\": r2,  # Adicionando o R²\n",
    "        \"Acurácia\": accuracy\n",
    "    }\n",
    "\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f0e1a695-0a5f-4a9c-82e6-9d9c949425d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_linear(df, target_column):\n",
    "    \"\"\"\n",
    "    Treina um modelo de Regressão Linear Simples em dados de séries temporais e retorna as métricas de desempenho.\n",
    "\n",
    "    Parâmetros:\n",
    "        df (pd.DataFrame): DataFrame com os dados.\n",
    "        target_column (str): Nome da coluna de destino (target).\n",
    "\n",
    "    Retorna:\n",
    "        dict: Dicionário com métricas de desempenho (Loss, MSE, RMSE, MAE, MAPE, Acurácia).\n",
    "    \"\"\"\n",
    "    # Separando as variáveis independentes (X) e dependente (y)\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "\n",
    "    # Dividindo os dados em 80% para treino e 20% para teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    # Escalonando os dados para que os valores estejam entre 0 e 1\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Chamando a função para criar o modelo de Regressão Linear Simples\n",
    "    model = model_linear_simple((X_train_scaled.shape[1],))\n",
    "\n",
    "    # Treinando o modelo\n",
    "    history = model.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        verbose=1,\n",
    "        validation_data=(X_test_scaled, y_test)\n",
    "    )\n",
    "\n",
    "    # Prevendo no conjunto de teste\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Calculando métricas adicionais\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(y_test - y_pred))\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "    # Coeficiente de determinação (R²)\n",
    "    ss_total = np.sum((y_test - np.mean(y_test)) ** 2)  # Soma dos quadrados totais\n",
    "    ss_residual = np.sum((y_test - y_pred.flatten()) ** 2)  # Soma dos quadrados residuais\n",
    "    r2 = 1 - (ss_residual / ss_total)\n",
    "\n",
    "    # Acurácia considerando 2% de margem de erro\n",
    "    margin = 0.02\n",
    "    accuracy = accuracy_score(\n",
    "        (np.abs(y_test - y_pred.flatten()) <= margin * y_test).astype(int),\n",
    "        np.ones_like(y_test)\n",
    "    )\n",
    "\n",
    "    # Montando o dicionário de métricas\n",
    "    metrics_dict = {\n",
    "        \"Loss\": history.history['loss'][-1],\n",
    "        \"MSE\": mse,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"MAPE\": mape,\n",
    "        \"R²\": r2,  # Adicionando o R²\n",
    "        \"Acurácia\": accuracy\n",
    "    }\n",
    "\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c65c84-54e4-479f-a79e-317d6edba92e",
   "metadata": {},
   "source": [
    "### 2.6 Treinamento de Todos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0d6da3-dc81-4b8b-ac1b-c4ea1f65eb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_all(df, target_column, name_model):\n",
    "    \"\"\"\n",
    "    Treina um modelo LSTM em dados de séries temporais e retorna as métricas de desempenho.\n",
    "\n",
    "    Parâmetros:\n",
    "        df (pd.DataFrame): DataFrame com os dados.\n",
    "        target_column (str): Nome da coluna de destino (target).\n",
    "\n",
    "    Retorna:\n",
    "        dict: Dicionário com métricas de desempenho (Loss, MSE, RMSE, MAE, MAPE, Acurácia).\n",
    "    \"\"\"\n",
    "    # Separando as variáveis independentes (X) e dependente (y)\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "\n",
    "    # Dividindo os dados em 80% para treino e 20% para teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    # Escalonando os dados para que os valores estejam entre 0 e 1\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Reshape dos dados para LSTM (adicionar dimensão para timesteps)\n",
    "    X_train_scaled = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "    X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "    # Mapeamento de nomes de modelos para funções\n",
    "    model_mapping = {\n",
    "    'model_1': model_1,\n",
    "    'model_2': model_2,\n",
    "    'model_3': model_3,\n",
    "    'model_linear_simple': model_linear_simple,\n",
    "    }\n",
    "\n",
    "    # Chamando o modelo\n",
    "    if name_model == 'model_3' or name_model == 'model_linear_simple':\n",
    "        model = model_mapping[name_model]((X_train.shape[1],))\n",
    "    \n",
    "        # Treinando o modelo\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            verbose=1,\n",
    "            validation_data=(X_test, y_test)\n",
    "        )\n",
    "        # Prevendo no conjunto de teste\n",
    "        y_pred = model.predict(X_test)\n",
    "    else:\n",
    "        model = model_mapping[name_model]((X_train_scaled.shape[1], X_train_scaled.shape[2]), learning_rate=0.001)\n",
    "            # Configurando EarlyStopping\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "        # Treinando o modelo\n",
    "        history = model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            #X_train, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            validation_data=(X_test_scaled, y_test),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=1\n",
    "        )\n",
    "        # Prevendo no conjunto de teste\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Calculando métricas adicionais\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(y_test - y_pred))\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "    # Coeficiente de determinação (R²)\n",
    "    ss_total = np.sum((y_test - np.mean(y_test)) ** 2)  # Soma dos quadrados totais\n",
    "    ss_residual = np.sum((y_test - y_pred.flatten()) ** 2)  # Soma dos quadrados residuais\n",
    "    r2 = 1 - (ss_residual / ss_total)\n",
    "\n",
    "    # Acurácia considerando 2% de margem de erro\n",
    "    margin = 0.02\n",
    "    accuracy = accuracy_score(\n",
    "        (np.abs(y_test - y_pred.flatten()) <= margin * y_test).astype(int),\n",
    "        np.ones_like(y_test)\n",
    "    )\n",
    "\n",
    "    # Montando o dicionário de métricas\n",
    "    metrics_dict = {\n",
    "        \"Loss\": history.history['loss'][-1],\n",
    "        \"MSE\": mse,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"MAPE\": mape,\n",
    "        \"R²\": r2,  # Adicionando o R²\n",
    "        \"Acurácia\": accuracy\n",
    "    }\n",
    "\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2e161c95-4807-4dd8-9553-58e96413abe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def train_model_sliding_window(df, target_column, model, window_size=5, test_size=0.2, epochs=50, batch_size=32, patience=10):\n",
    "    \"\"\"\n",
    "    Treina um modelo em dados de séries temporais usando janela deslizante e retorna as métricas de desempenho.\n",
    "\n",
    "    Parâmetros:\n",
    "        df (pd.DataFrame): DataFrame com os dados.\n",
    "        target_column (str): Nome da coluna de destino (target).\n",
    "        model (callable): Função que define o modelo Keras.\n",
    "        window_size (int): Tamanho da janela deslizante.\n",
    "        test_size (float): Proporção dos dados para teste.\n",
    "        epochs (int): Número de épocas de treinamento.\n",
    "        batch_size (int): Tamanho do lote para treinamento.\n",
    "        patience (int): Paciência para Early Stopping.\n",
    "\n",
    "    Retorna:\n",
    "        dict: Dicionário com métricas de desempenho e histórico de treinamento.\n",
    "        model: Modelo treinado.\n",
    "        scaler: Scaler utilizado.\n",
    "    \"\"\"\n",
    "\n",
    "    # Separando as variáveis independentes (X) e dependente (y)\n",
    "    X = df.drop(columns=[target_column]).values\n",
    "    y = df[target_column].values\n",
    "\n",
    "    # Escalonando os dados\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Criando dados com janela deslizante (usando list comprehension para concisão)\n",
    "    X_sliding, y_sliding = [], []\n",
    "    for i in range(len(X_scaled) - window_size):\n",
    "        X_sliding.append(X_scaled[i:i + window_size])\n",
    "        y_sliding.append(y[i + window_size])\n",
    "    X_sliding = np.array(X_sliding)\n",
    "    y_sliding = np.array(y_sliding)\n",
    "\n",
    "    # Dividindo os dados em treino e teste (usando train_test_split para melhor controle)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_sliding, y_sliding, test_size=test_size, shuffle=False  # shuffle=False é crucial para séries temporais\n",
    "    )\n",
    "\n",
    "    # Instanciando o modelo\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2]) if len(X_train.shape) == 3 else (X_train.shape[1],)\n",
    "    model = model_1(input_shape)\n",
    "\n",
    "    # Configurando EarlyStopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "\n",
    "    # Treinando o modelo\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Prevendo no conjunto de teste\n",
    "    y_pred = model.predict(X_test).flatten() # Achatando o array de predições\n",
    "\n",
    "    # Calculando métricas\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100 if not np.any(y_test == 0) else np.inf # Tratando divisão por zero no MAPE\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Acurácia com margem de erro (melhoria na lógica)\n",
    "    margin_percentage = 0.02\n",
    "    margin = margin_percentage * np.abs(y_test)\n",
    "    correct_predictions = np.abs(y_test - y_pred) <= margin\n",
    "    accuracy = np.mean(correct_predictions)\n",
    "\n",
    "    # Montando o dicionário de métricas\n",
    "    metrics_dict = {\n",
    "        \"Loss\": history.history['loss'][-1],\n",
    "        \"Val_Loss\": history.history['val_loss'][-1], # Adicionado Val_loss\n",
    "        \"MSE\": mse,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"MAPE\": mape,\n",
    "        \"R²\": r2,\n",
    "        \"Acurácia\": accuracy,\n",
    "        \"history\": history.history # Inclui o histórico completo para análise posterior\n",
    "    }\n",
    "\n",
    "    #return metrics_dict, model, scaler\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b6d99d-8ca8-472d-a596-d6fab4db40a3",
   "metadata": {},
   "source": [
    "## 3 - Definição dos Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6fe09d-b231-4c2a-a789-9ba10e22d53a",
   "metadata": {},
   "source": [
    "### 3.1 Modelo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1524c5ac-6450-4637-ba4e-ce9d12f4dbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 1\n",
    "\n",
    "def model_1(input_shape, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Cria e compila um modelo LSTM.\n",
    "\n",
    "    Parâmetros:\n",
    "        input_shape (tuple): A forma da entrada (timesteps, features).\n",
    "        learning_rate (float): Taxa de aprendizado para o otimizador Adam.\n",
    "\n",
    "    Retorna:\n",
    "        keras.Model: Modelo LSTM compilado.\n",
    "    \"\"\"\n",
    "    # Criando o modelo com o uso explícito de Input\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        LSTM(16, return_sequences=False),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    # Compilando o modelo\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mse', 'mae', 'mape']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b6bc9c-3a83-4fee-9072-1cb953fa6b80",
   "metadata": {},
   "source": [
    "### 3.2 Modelo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f11d0320-8aab-4b94-b47f-21c4abc71f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 2\n",
    "\n",
    "def model_2(input_shape, learning_rate=0.001, dropout_rate=0.03):\n",
    "    \"\"\"\n",
    "    Cria e compila um modelo LSTM complexo com várias camadas e dropout.\n",
    "\n",
    "    Parâmetros:\n",
    "        input_shape (tuple): A forma da entrada (timesteps, features).\n",
    "        learning_rate (float): Taxa de aprendizado para o otimizador Adam.\n",
    "        dropout_rate (float): Taxa de dropout aplicada nas últimas camadas.\n",
    "\n",
    "    Retorna:\n",
    "        keras.Model: Modelo LSTM compilado.\n",
    "    \"\"\"\n",
    "    # Criando o modelo com o uso explícito de Input\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        LSTM(200, activation='tanh', recurrent_activation='sigmoid', return_sequences=True),\n",
    "        LSTM(300, activation='tanh', recurrent_activation='sigmoid', return_sequences=True),\n",
    "        LSTM(400, activation='tanh', recurrent_activation='sigmoid', return_sequences=True),\n",
    "        Dropout(dropout_rate),  # Dropout na penúltima camada LSTM\n",
    "        LSTM(400, activation='tanh', recurrent_activation='sigmoid', return_sequences=False),\n",
    "        Dropout(dropout_rate),  # Dropout na última camada LSTM\n",
    "        Dense(1)  # Camada de saída\n",
    "    ])\n",
    "\n",
    "    # Compilando o modelo\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mse', 'mae', 'mape']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a42a71-c592-4a38-83f5-7560f5ee2399",
   "metadata": {},
   "source": [
    "### 3.3 Modelo 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "08d126d8-0c43-4700-8581-58ba0af2b8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 3\n",
    "def model_3(input_shape):\n",
    "    \"\"\"\n",
    "    Cria e compila um modelo denso com 3 camadas.\n",
    "\n",
    "    Parâmetros:\n",
    "        input_shape (tuple): A forma da entrada (features,).\n",
    "        learning_rate (float): Taxa de aprendizado para o otimizador Adam.\n",
    "\n",
    "    Retorna:\n",
    "        keras.Model: Modelo denso compilado.\n",
    "    \"\"\"\n",
    "    learning_rate=0.001\n",
    "    \n",
    "    # Criando o modelo\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        Dense(32, activation='relu'),  # Primeira camada Dense\n",
    "        Dense(8, activation='relu'),                            # Segunda camada Dense\n",
    "        Dense(1)                                                # Camada de saída\n",
    "    ])\n",
    "\n",
    "    # Compilando o modelo\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mse', 'mae', 'mape']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb2aeef-67fc-4f95-aa03-434cba701299",
   "metadata": {},
   "source": [
    "### 3.4 Modelo 4 - model_linear_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "07a9f615-af99-4fdc-80bb-866a51e70772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL: Regressão Linear Simples\n",
    "\n",
    "def model_linear_simple(input_shape):\n",
    "    \"\"\"\n",
    "    Cria um modelo de Regressão Linear Simples.\n",
    "\n",
    "    Parâmetros:\n",
    "        input_shape (tuple): A forma da entrada (features,).\n",
    "\n",
    "    Retorna:\n",
    "        keras.Model: Modelo de regressão linear simples compilado.\n",
    "    \"\"\"\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "\n",
    "    # Criando o modelo\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        Dense(1, activation='linear')  # Saída linear para regressão\n",
    "    ])\n",
    "\n",
    "    # Compilando o modelo\n",
    "    model.compile(\n",
    "        optimizer='adam',  # Otimizador Adam padrão\n",
    "        loss='mean_squared_error',  # Perda de erro médio quadrático\n",
    "        metrics=['mse', 'mae', 'mape']  # Métricas úteis para regressão\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114a904b-db68-4961-930e-ece7a13ec837",
   "metadata": {},
   "source": [
    "## 4 - Treino dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68a80a5-a08b-4a58-b4cc-76dbe9c3ba4b",
   "metadata": {},
   "source": [
    "### 4.1 Função Principal - process_stocks_and_save_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6d97ea41-515c-41df-b2dc-bdae4fdde8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stocks_and_save_metrics(stock_list, num_combination, name_model):\n",
    "    \"\"\"\n",
    "    Processa uma lista de ações, treina o modelo LSTM para cada uma e salva as métricas em um DataFrame.\n",
    "\n",
    "    Parâmetros:\n",
    "        stock_list (list): Lista de ações (str).\n",
    "        get_stock_data_func (function): Função para obter os dados de cada ação.\n",
    "            Deve retornar um DataFrame com os dados da ação e o nome da coluna de destino (target).\n",
    "\n",
    "    Retorna:\n",
    "        pd.DataFrame: DataFrame contendo o nome da ação, descrição dos dados, nome do modelo e as métricas.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for stock in stock_list:\n",
    "        print(f\"{name_model}: Processando ação: {stock}, combination: {num_combination}...\")\n",
    "\n",
    "        # Obtém os dados da ação\n",
    "        df = all_stock_data[stock]\n",
    "        # Realizar as combination\n",
    "        df, description_combination = make_combination_data(df, num_combination)\n",
    "        # Definir o alvo\n",
    "        df, target_column = define_target(df)\n",
    "\n",
    "        # Treina o modelo e coleta as métricas\n",
    "        #metrics = train_lstm_model(df, target_column, name_model)\n",
    "        #metrics = train_model_all(df, target_column, name_model)\n",
    "        #metrics = train_model_windows(df, target_column, name_model)\n",
    "        #metrics = train_model_linear(df, target_column)\n",
    "        metrics = train_model_sliding_window(df, target_column, name_model) \n",
    "\n",
    "        # Salva os resultados no formato desejado\n",
    "        results.append({\n",
    "            \"Stock\": stock,\n",
    "            \"Description\": description_combination,\n",
    "            \"Model\": name_model,\n",
    "            **metrics\n",
    "        })\n",
    "\n",
    "    # Retorna os resultados em um DataFrame\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "    # Normalização\n",
    "    # Normalizar os colunas\n",
    "    #columns = ['close','open', 'high', 'low', 'mms_5', 'mms_30', 'mme_5','mme_30']\n",
    "    \n",
    "    # Normalizar\n",
    "    #df = normalize_columns_2(df, columns, 30)\n",
    "    \n",
    "    return df, 'close_next_day', description_combination, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50951950-1733-4fc2-abe6-c0ae6149fa40",
   "metadata": {},
   "source": [
    "### 4.2 Rodando em todas as Empresas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8ed830c6-14e7-4364-9ca0-23e8423a3bab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados para: PETR4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando combinações:   0%|                                                                   | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_1: Processando ação: PETR4, combination: 1...\n",
      "Epoch 1/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.1252 - mae: 0.2699 - mape: 38263.0078 - mse: 0.1252 - val_loss: 0.0019 - val_mae: 0.0330 - val_mape: 8.4687 - val_mse: 0.0019\n",
      "Epoch 2/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0032 - mae: 0.0440 - mape: 104138.7031 - mse: 0.0032 - val_loss: 9.3976e-04 - val_mae: 0.0212 - val_mape: 5.1139 - val_mse: 9.3976e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8550e-04 - mae: 0.0215 - mape: 2402.4290 - mse: 7.8550e-04 - val_loss: 9.0899e-04 - val_mae: 0.0211 - val_mape: 5.0572 - val_mse: 9.0899e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.3399e-04 - mae: 0.0185 - mape: 25120.5117 - mse: 6.3399e-04 - val_loss: 9.0423e-04 - val_mae: 0.0211 - val_mape: 5.0573 - val_mse: 9.0423e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.5302e-04 - mae: 0.0176 - mape: 14238.7979 - mse: 5.5302e-04 - val_loss: 8.9438e-04 - val_mae: 0.0210 - val_mape: 5.0442 - val_mse: 8.9438e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2947e-04 - mae: 0.0170 - mape: 40079.7773 - mse: 5.2947e-04 - val_loss: 9.0210e-04 - val_mae: 0.0216 - val_mape: 5.1772 - val_mse: 9.0210e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.1728e-04 - mae: 0.0167 - mape: 3841.8555 - mse: 5.1728e-04 - val_loss: 8.9135e-04 - val_mae: 0.0212 - val_mape: 5.1139 - val_mse: 8.9135e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8648e-04 - mae: 0.0161 - mape: 12669.6221 - mse: 4.8648e-04 - val_loss: 8.8164e-04 - val_mae: 0.0210 - val_mape: 5.0625 - val_mse: 8.8164e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0495e-04 - mae: 0.0165 - mape: 11136.4697 - mse: 5.0495e-04 - val_loss: 8.7767e-04 - val_mae: 0.0208 - val_mape: 5.0133 - val_mse: 8.7767e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2672e-04 - mae: 0.0162 - mape: 61266.7109 - mse: 5.2672e-04 - val_loss: 8.7512e-04 - val_mae: 0.0207 - val_mape: 5.0112 - val_mse: 8.7512e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1405e-04 - mae: 0.0165 - mape: 4006.8408 - mse: 5.1405e-04 - val_loss: 8.6760e-04 - val_mae: 0.0204 - val_mape: 4.9329 - val_mse: 8.6760e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9726e-04 - mae: 0.0164 - mape: 58143.5156 - mse: 4.9726e-04 - val_loss: 8.7932e-04 - val_mae: 0.0205 - val_mape: 4.9620 - val_mse: 8.7932e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4438e-04 - mae: 0.0154 - mape: 5002.2671 - mse: 4.4438e-04 - val_loss: 8.6281e-04 - val_mae: 0.0205 - val_mape: 4.9542 - val_mse: 8.6281e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7367e-04 - mae: 0.0156 - mape: 8630.8438 - mse: 4.7367e-04 - val_loss: 8.6618e-04 - val_mae: 0.0203 - val_mape: 4.9168 - val_mse: 8.6618e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7169e-04 - mae: 0.0158 - mape: 7018.5391 - mse: 4.7169e-04 - val_loss: 8.4363e-04 - val_mae: 0.0202 - val_mape: 4.8926 - val_mse: 8.4363e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6814e-04 - mae: 0.0157 - mape: 416.2580 - mse: 4.6814e-04 - val_loss: 8.5591e-04 - val_mae: 0.0202 - val_mape: 4.8815 - val_mse: 8.5591e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6552e-04 - mae: 0.0155 - mape: 4306.4536 - mse: 4.6552e-04 - val_loss: 8.7031e-04 - val_mae: 0.0202 - val_mape: 4.8910 - val_mse: 8.7031e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7284e-04 - mae: 0.0156 - mape: 25606.9590 - mse: 4.7284e-04 - val_loss: 8.1781e-04 - val_mae: 0.0199 - val_mape: 4.8088 - val_mse: 8.1781e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8516e-04 - mae: 0.0158 - mape: 2047.3820 - mse: 4.8516e-04 - val_loss: 8.1564e-04 - val_mae: 0.0198 - val_mape: 4.7956 - val_mse: 8.1564e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7244e-04 - mae: 0.0157 - mape: 13794.3750 - mse: 4.7244e-04 - val_loss: 7.9963e-04 - val_mae: 0.0198 - val_mape: 4.7616 - val_mse: 7.9963e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0189e-04 - mae: 0.0159 - mape: 8781.0674 - mse: 5.0189e-04 - val_loss: 8.0228e-04 - val_mae: 0.0201 - val_mape: 4.8169 - val_mse: 8.0228e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3448e-04 - mae: 0.0153 - mape: 1905.5758 - mse: 4.3448e-04 - val_loss: 8.1055e-04 - val_mae: 0.0204 - val_mape: 4.8956 - val_mse: 8.1055e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0318e-04 - mae: 0.0159 - mape: 7018.9448 - mse: 5.0318e-04 - val_loss: 8.2843e-04 - val_mae: 0.0196 - val_mape: 4.7365 - val_mse: 8.2843e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4831e-04 - mae: 0.0152 - mape: 18242.1660 - mse: 4.4831e-04 - val_loss: 8.0871e-04 - val_mae: 0.0206 - val_mape: 4.9215 - val_mse: 8.0871e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3991e-04 - mae: 0.0152 - mape: 6117.1763 - mse: 4.3991e-04 - val_loss: 8.3128e-04 - val_mae: 0.0213 - val_mape: 5.0446 - val_mse: 8.3128e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4234e-04 - mae: 0.0151 - mape: 2096.1707 - mse: 4.4234e-04 - val_loss: 7.5962e-04 - val_mae: 0.0193 - val_mape: 4.6429 - val_mse: 7.5962e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.5146e-04 - mae: 0.0151 - mape: 5950.9131 - mse: 4.5146e-04 - val_loss: 7.8285e-04 - val_mae: 0.0202 - val_mape: 4.8174 - val_mse: 7.8285e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2376e-04 - mae: 0.0149 - mape: 1056.3107 - mse: 4.2376e-04 - val_loss: 7.4426e-04 - val_mae: 0.0190 - val_mape: 4.5607 - val_mse: 7.4426e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2035e-04 - mae: 0.0146 - mape: 544.8660 - mse: 4.2035e-04 - val_loss: 7.5421e-04 - val_mae: 0.0188 - val_mape: 4.5243 - val_mse: 7.5421e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1424e-04 - mae: 0.0148 - mape: 1941.6555 - mse: 4.1424e-04 - val_loss: 8.4010e-04 - val_mae: 0.0197 - val_mape: 4.7345 - val_mse: 8.4010e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5205e-04 - mae: 0.0157 - mape: 1708.4701 - mse: 4.5205e-04 - val_loss: 8.0049e-04 - val_mae: 0.0191 - val_mape: 4.6084 - val_mse: 8.0049e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9135e-04 - mae: 0.0145 - mape: 633.8489 - mse: 3.9135e-04 - val_loss: 7.1177e-04 - val_mae: 0.0185 - val_mape: 4.4350 - val_mse: 7.1177e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1144e-04 - mae: 0.0146 - mape: 9487.9170 - mse: 4.1144e-04 - val_loss: 7.8519e-04 - val_mae: 0.0190 - val_mape: 4.5684 - val_mse: 7.8519e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0963e-04 - mae: 0.0145 - mape: 1250.5350 - mse: 4.0963e-04 - val_loss: 7.1563e-04 - val_mae: 0.0181 - val_mape: 4.3647 - val_mse: 7.1563e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9402e-04 - mae: 0.0146 - mape: 356.5244 - mse: 3.9402e-04 - val_loss: 7.1240e-04 - val_mae: 0.0182 - val_mape: 4.3784 - val_mse: 7.1240e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9381e-04 - mae: 0.0144 - mape: 4165.4941 - mse: 3.9381e-04 - val_loss: 6.9536e-04 - val_mae: 0.0180 - val_mape: 4.3328 - val_mse: 6.9536e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9015e-04 - mae: 0.0142 - mape: 9484.5576 - mse: 3.9015e-04 - val_loss: 6.9076e-04 - val_mae: 0.0186 - val_mape: 4.4286 - val_mse: 6.9076e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8953e-04 - mae: 0.0143 - mape: 865.8203 - mse: 3.8953e-04 - val_loss: 7.1282e-04 - val_mae: 0.0193 - val_mape: 4.5630 - val_mse: 7.1282e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7688e-04 - mae: 0.0142 - mape: 9031.9170 - mse: 3.7688e-04 - val_loss: 6.7164e-04 - val_mae: 0.0178 - val_mape: 4.2724 - val_mse: 6.7164e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5896e-04 - mae: 0.0138 - mape: 13544.7930 - mse: 3.5896e-04 - val_loss: 6.7807e-04 - val_mae: 0.0186 - val_mape: 4.3927 - val_mse: 6.7807e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7970e-04 - mae: 0.0142 - mape: 2807.0605 - mse: 3.7970e-04 - val_loss: 6.5289e-04 - val_mae: 0.0173 - val_mape: 4.1459 - val_mse: 6.5289e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6618e-04 - mae: 0.0139 - mape: 6193.4941 - mse: 3.6618e-04 - val_loss: 6.4301e-04 - val_mae: 0.0177 - val_mape: 4.1923 - val_mse: 6.4301e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7878e-04 - mae: 0.0140 - mape: 4675.8618 - mse: 3.7878e-04 - val_loss: 6.4127e-04 - val_mae: 0.0171 - val_mape: 4.0947 - val_mse: 6.4127e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5067e-04 - mae: 0.0132 - mape: 1197.8605 - mse: 3.5067e-04 - val_loss: 7.1681e-04 - val_mae: 0.0198 - val_mape: 4.5879 - val_mse: 7.1681e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6042e-04 - mae: 0.0138 - mape: 450.3390 - mse: 3.6042e-04 - val_loss: 6.3631e-04 - val_mae: 0.0170 - val_mape: 4.0612 - val_mse: 6.3631e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5954e-04 - mae: 0.0136 - mape: 1723.0631 - mse: 3.5954e-04 - val_loss: 7.6338e-04 - val_mae: 0.0189 - val_mape: 4.4992 - val_mse: 7.6338e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5546e-04 - mae: 0.0139 - mape: 14371.8662 - mse: 3.5546e-04 - val_loss: 6.5044e-04 - val_mae: 0.0171 - val_mape: 4.0826 - val_mse: 6.5044e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4699e-04 - mae: 0.0134 - mape: 2454.1892 - mse: 3.4699e-04 - val_loss: 6.6661e-04 - val_mae: 0.0173 - val_mape: 4.1385 - val_mse: 6.6661e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7160e-04 - mae: 0.0140 - mape: 1576.9119 - mse: 3.7160e-04 - val_loss: 6.7378e-04 - val_mae: 0.0189 - val_mape: 4.3757 - val_mse: 6.7378e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3846e-04 - mae: 0.0136 - mape: 14332.0557 - mse: 3.3846e-04 - val_loss: 7.7664e-04 - val_mae: 0.0212 - val_mape: 4.8610 - val_mse: 7.7664e-04\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando combinações:  14%|████████▍                                                  | 1/7 [00:16<01:37, 16.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_1: Processando ação: PETR4, combination: 2...\n",
      "Epoch 1/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0749 - mae: 0.2009 - mape: 117237.2266 - mse: 0.0749 - val_loss: 0.0060 - val_mae: 0.0657 - val_mape: 13.7765 - val_mse: 0.0060\n",
      "Epoch 2/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0423 - mape: 234928.7344 - mse: 0.0029 - val_loss: 0.0010 - val_mae: 0.0237 - val_mape: 5.6118 - val_mse: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.2172e-04 - mae: 0.0222 - mape: 7246.3711 - mse: 8.2172e-04 - val_loss: 9.0723e-04 - val_mae: 0.0218 - val_mape: 5.2350 - val_mse: 9.0723e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6296e-04 - mae: 0.0176 - mape: 4033.7913 - mse: 5.6296e-04 - val_loss: 9.5845e-04 - val_mae: 0.0220 - val_mape: 5.2542 - val_mse: 9.5845e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.1979e-04 - mae: 0.0167 - mape: 3418.2686 - mse: 5.1979e-04 - val_loss: 9.3511e-04 - val_mae: 0.0224 - val_mape: 5.3590 - val_mse: 9.3511e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.5328e-04 - mae: 0.0173 - mape: 10944.5908 - mse: 5.5328e-04 - val_loss: 9.4820e-04 - val_mae: 0.0218 - val_mape: 5.2172 - val_mse: 9.4820e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.5416e-04 - mae: 0.0167 - mape: 3836.5596 - mse: 5.5416e-04 - val_loss: 9.6927e-04 - val_mae: 0.0218 - val_mape: 5.1905 - val_mse: 9.6927e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7295e-04 - mae: 0.0161 - mape: 12086.4082 - mse: 4.7295e-04 - val_loss: 9.5443e-04 - val_mae: 0.0217 - val_mape: 5.1757 - val_mse: 9.5443e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0190e-04 - mae: 0.0164 - mape: 16041.1211 - mse: 5.0190e-04 - val_loss: 8.9633e-04 - val_mae: 0.0219 - val_mape: 5.2380 - val_mse: 8.9633e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0996e-04 - mae: 0.0166 - mape: 763.5043 - mse: 5.0996e-04 - val_loss: 8.8216e-04 - val_mae: 0.0210 - val_mape: 5.0223 - val_mse: 8.8216e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7285e-04 - mae: 0.0159 - mape: 10651.0488 - mse: 4.7285e-04 - val_loss: 8.5243e-04 - val_mae: 0.0206 - val_mape: 4.9416 - val_mse: 8.5243e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9125e-04 - mae: 0.0162 - mape: 1754.4420 - mse: 4.9125e-04 - val_loss: 8.7062e-04 - val_mae: 0.0205 - val_mape: 4.9018 - val_mse: 8.7062e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8932e-04 - mae: 0.0163 - mape: 12722.4717 - mse: 4.8932e-04 - val_loss: 9.3437e-04 - val_mae: 0.0211 - val_mape: 5.0320 - val_mse: 9.3437e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9489e-04 - mae: 0.0162 - mape: 506.5552 - mse: 4.9489e-04 - val_loss: 8.1560e-04 - val_mae: 0.0202 - val_mape: 4.8548 - val_mse: 8.1560e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4980e-04 - mae: 0.0158 - mape: 13392.4268 - mse: 4.4980e-04 - val_loss: 8.3781e-04 - val_mae: 0.0207 - val_mape: 4.9842 - val_mse: 8.3781e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8165e-04 - mae: 0.0160 - mape: 3809.9585 - mse: 4.8165e-04 - val_loss: 8.0150e-04 - val_mae: 0.0197 - val_mape: 4.7228 - val_mse: 8.0150e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4088e-04 - mae: 0.0153 - mape: 17918.4824 - mse: 4.4088e-04 - val_loss: 8.1367e-04 - val_mae: 0.0197 - val_mape: 4.7233 - val_mse: 8.1367e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6274e-04 - mae: 0.0155 - mape: 2380.9883 - mse: 4.6274e-04 - val_loss: 7.9079e-04 - val_mae: 0.0202 - val_mape: 4.8247 - val_mse: 7.9079e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2934e-04 - mae: 0.0152 - mape: 1550.2056 - mse: 4.2934e-04 - val_loss: 7.8631e-04 - val_mae: 0.0200 - val_mape: 4.7991 - val_mse: 7.8631e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3516e-04 - mae: 0.0152 - mape: 838.7635 - mse: 4.3516e-04 - val_loss: 7.8005e-04 - val_mae: 0.0194 - val_mape: 4.6542 - val_mse: 7.8005e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3063e-04 - mae: 0.0151 - mape: 6516.9922 - mse: 4.3063e-04 - val_loss: 7.8579e-04 - val_mae: 0.0191 - val_mape: 4.5760 - val_mse: 7.8579e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9808e-04 - mae: 0.0147 - mape: 11406.4697 - mse: 3.9808e-04 - val_loss: 7.6912e-04 - val_mae: 0.0198 - val_mape: 4.7436 - val_mse: 7.6912e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0970e-04 - mae: 0.0148 - mape: 5417.0444 - mse: 4.0970e-04 - val_loss: 7.7210e-04 - val_mae: 0.0201 - val_mape: 4.7939 - val_mse: 7.7210e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4565e-04 - mae: 0.0154 - mape: 24616.2129 - mse: 4.4565e-04 - val_loss: 7.3314e-04 - val_mae: 0.0186 - val_mape: 4.4682 - val_mse: 7.3314e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4783e-04 - mae: 0.0150 - mape: 1490.8845 - mse: 4.4783e-04 - val_loss: 7.1946e-04 - val_mae: 0.0186 - val_mape: 4.4496 - val_mse: 7.1946e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2949e-04 - mae: 0.0151 - mape: 3993.5156 - mse: 4.2949e-04 - val_loss: 7.3476e-04 - val_mae: 0.0185 - val_mape: 4.4422 - val_mse: 7.3476e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9526e-04 - mae: 0.0145 - mape: 7122.4692 - mse: 3.9526e-04 - val_loss: 7.2062e-04 - val_mae: 0.0187 - val_mape: 4.4712 - val_mse: 7.2062e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4254e-04 - mae: 0.0152 - mape: 4220.4868 - mse: 4.4254e-04 - val_loss: 8.5422e-04 - val_mae: 0.0199 - val_mape: 4.7434 - val_mse: 8.5422e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2673e-04 - mae: 0.0151 - mape: 4403.5234 - mse: 4.2673e-04 - val_loss: 7.3712e-04 - val_mae: 0.0183 - val_mape: 4.4098 - val_mse: 7.3712e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5066e-04 - mae: 0.0150 - mape: 1725.6768 - mse: 4.5066e-04 - val_loss: 7.2029e-04 - val_mae: 0.0182 - val_mape: 4.3649 - val_mse: 7.2029e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7132e-04 - mae: 0.0140 - mape: 11854.2842 - mse: 3.7132e-04 - val_loss: 6.9532e-04 - val_mae: 0.0186 - val_mape: 4.4324 - val_mse: 6.9532e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8651e-04 - mae: 0.0142 - mape: 3164.4727 - mse: 3.8651e-04 - val_loss: 7.0093e-04 - val_mae: 0.0188 - val_mape: 4.4665 - val_mse: 7.0093e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7202e-04 - mae: 0.0140 - mape: 10022.4824 - mse: 3.7202e-04 - val_loss: 6.7665e-04 - val_mae: 0.0180 - val_mape: 4.3012 - val_mse: 6.7665e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8838e-04 - mae: 0.0145 - mape: 1903.5778 - mse: 3.8838e-04 - val_loss: 6.8328e-04 - val_mae: 0.0180 - val_mape: 4.2928 - val_mse: 6.8328e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7252e-04 - mae: 0.0139 - mape: 1329.8912 - mse: 3.7252e-04 - val_loss: 6.6443e-04 - val_mae: 0.0179 - val_mape: 4.2532 - val_mse: 6.6443e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7575e-04 - mae: 0.0140 - mape: 7016.3809 - mse: 3.7575e-04 - val_loss: 6.7166e-04 - val_mae: 0.0179 - val_mape: 4.2731 - val_mse: 6.7166e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7219e-04 - mae: 0.0141 - mape: 17996.5352 - mse: 3.7219e-04 - val_loss: 6.9477e-04 - val_mae: 0.0189 - val_mape: 4.4760 - val_mse: 6.9477e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5021e-04 - mae: 0.0134 - mape: 6740.5679 - mse: 3.5021e-04 - val_loss: 7.7291e-04 - val_mae: 0.0209 - val_mape: 4.8937 - val_mse: 7.7291e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9236e-04 - mae: 0.0146 - mape: 4867.9321 - mse: 3.9236e-04 - val_loss: 7.6855e-04 - val_mae: 0.0209 - val_mape: 4.8463 - val_mse: 7.6855e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5870e-04 - mae: 0.0139 - mape: 4533.5874 - mse: 3.5870e-04 - val_loss: 6.8753e-04 - val_mae: 0.0190 - val_mape: 4.4650 - val_mse: 6.8753e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9836e-04 - mae: 0.0145 - mape: 2243.3621 - mse: 3.9836e-04 - val_loss: 6.5117e-04 - val_mae: 0.0174 - val_mape: 4.1577 - val_mse: 6.5117e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7436e-04 - mae: 0.0141 - mape: 5380.5669 - mse: 3.7436e-04 - val_loss: 6.8772e-04 - val_mae: 0.0191 - val_mape: 4.4720 - val_mse: 6.8772e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5088e-04 - mae: 0.0134 - mape: 11525.9990 - mse: 3.5088e-04 - val_loss: 7.0466e-04 - val_mae: 0.0195 - val_mape: 4.5565 - val_mse: 7.0466e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6315e-04 - mae: 0.0136 - mape: 8788.1240 - mse: 3.6315e-04 - val_loss: 6.4232e-04 - val_mae: 0.0174 - val_mape: 4.1457 - val_mse: 6.4232e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7291e-04 - mae: 0.0139 - mape: 937.9156 - mse: 3.7291e-04 - val_loss: 6.2924e-04 - val_mae: 0.0176 - val_mape: 4.1467 - val_mse: 6.2924e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4568e-04 - mae: 0.0134 - mape: 4754.3770 - mse: 3.4568e-04 - val_loss: 6.2433e-04 - val_mae: 0.0173 - val_mape: 4.0970 - val_mse: 6.2433e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2280e-04 - mae: 0.0131 - mape: 1494.3416 - mse: 3.2280e-04 - val_loss: 6.2320e-04 - val_mae: 0.0173 - val_mape: 4.1008 - val_mse: 6.2320e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6122e-04 - mae: 0.0136 - mape: 2642.5681 - mse: 3.6122e-04 - val_loss: 6.2616e-04 - val_mae: 0.0175 - val_mape: 4.1282 - val_mse: 6.2616e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5861e-04 - mae: 0.0135 - mape: 440.0516 - mse: 3.5861e-04 - val_loss: 6.2647e-04 - val_mae: 0.0172 - val_mape: 4.0798 - val_mse: 6.2647e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4019e-04 - mae: 0.0132 - mape: 2443.2734 - mse: 3.4019e-04 - val_loss: 6.6724e-04 - val_mae: 0.0187 - val_mape: 4.3881 - val_mse: 6.6724e-04\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando combinações:  29%|████████████████▊                                          | 2/7 [00:32<01:20, 16.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_1: Processando ação: PETR4, combination: 3...\n",
      "Epoch 1/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0584 - mae: 0.1760 - mape: 73602.6875 - mse: 0.0584 - val_loss: 0.0021 - val_mae: 0.0357 - val_mape: 8.3773 - val_mse: 0.0021\n",
      "Epoch 2/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 - mae: 0.0270 - mape: 4685.3115 - mse: 0.0013 - val_loss: 0.0013 - val_mae: 0.0273 - val_mape: 6.5767 - val_mse: 0.0013\n",
      "Epoch 3/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.7528e-04 - mae: 0.0192 - mape: 877.1393 - mse: 6.7528e-04 - val_loss: 0.0011 - val_mae: 0.0243 - val_mape: 5.8336 - val_mse: 0.0011\n",
      "Epoch 4/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.5136e-04 - mae: 0.0171 - mape: 584.4545 - mse: 5.5136e-04 - val_loss: 0.0010 - val_mae: 0.0231 - val_mape: 5.5278 - val_mse: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0272e-04 - mae: 0.0162 - mape: 5880.4355 - mse: 5.0272e-04 - val_loss: 9.1057e-04 - val_mae: 0.0214 - val_mape: 5.1457 - val_mse: 9.1057e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7788e-04 - mae: 0.0158 - mape: 1688.4303 - mse: 4.7788e-04 - val_loss: 8.5520e-04 - val_mae: 0.0206 - val_mape: 4.9638 - val_mse: 8.5520e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7560e-04 - mae: 0.0158 - mape: 12267.5869 - mse: 4.7560e-04 - val_loss: 8.5696e-04 - val_mae: 0.0205 - val_mape: 4.9484 - val_mse: 8.5696e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8985e-04 - mae: 0.0158 - mape: 8180.6978 - mse: 4.8985e-04 - val_loss: 8.0771e-04 - val_mae: 0.0204 - val_mape: 4.8929 - val_mse: 8.0771e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2832e-04 - mae: 0.0149 - mape: 2868.0400 - mse: 4.2832e-04 - val_loss: 7.8236e-04 - val_mae: 0.0197 - val_mape: 4.7416 - val_mse: 7.8236e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3123e-04 - mae: 0.0151 - mape: 719.3135 - mse: 4.3123e-04 - val_loss: 7.9373e-04 - val_mae: 0.0195 - val_mape: 4.7161 - val_mse: 7.9373e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5296e-04 - mae: 0.0149 - mape: 9991.2129 - mse: 4.5296e-04 - val_loss: 7.7905e-04 - val_mae: 0.0200 - val_mape: 4.7900 - val_mse: 7.7905e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4870e-04 - mae: 0.0151 - mape: 1654.9888 - mse: 4.4870e-04 - val_loss: 7.5626e-04 - val_mae: 0.0193 - val_mape: 4.6492 - val_mse: 7.5626e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1218e-04 - mae: 0.0146 - mape: 17585.9141 - mse: 4.1218e-04 - val_loss: 7.8751e-04 - val_mae: 0.0192 - val_mape: 4.6468 - val_mse: 7.8751e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0848e-04 - mae: 0.0146 - mape: 2483.3499 - mse: 4.0848e-04 - val_loss: 8.0866e-04 - val_mae: 0.0195 - val_mape: 4.7015 - val_mse: 8.0866e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2513e-04 - mae: 0.0150 - mape: 13423.5430 - mse: 4.2513e-04 - val_loss: 7.6205e-04 - val_mae: 0.0199 - val_mape: 4.7540 - val_mse: 7.6205e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.5342e-04 - mae: 0.0154 - mape: 10763.3486 - mse: 4.5342e-04 - val_loss: 7.6798e-04 - val_mae: 0.0201 - val_mape: 4.8003 - val_mse: 7.6798e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7057e-04 - mae: 0.0140 - mape: 1693.2769 - mse: 3.7057e-04 - val_loss: 7.3219e-04 - val_mae: 0.0187 - val_mape: 4.4969 - val_mse: 7.3219e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8939e-04 - mae: 0.0142 - mape: 21424.3340 - mse: 3.8939e-04 - val_loss: 7.2435e-04 - val_mae: 0.0185 - val_mape: 4.4553 - val_mse: 7.2435e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8315e-04 - mae: 0.0142 - mape: 1014.8196 - mse: 3.8315e-04 - val_loss: 7.1343e-04 - val_mae: 0.0188 - val_mape: 4.4960 - val_mse: 7.1343e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9113e-04 - mae: 0.0142 - mape: 13028.6445 - mse: 3.9113e-04 - val_loss: 7.2117e-04 - val_mae: 0.0183 - val_mape: 4.4186 - val_mse: 7.2117e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0103e-04 - mae: 0.0144 - mape: 818.9886 - mse: 4.0103e-04 - val_loss: 7.1687e-04 - val_mae: 0.0190 - val_mape: 4.5410 - val_mse: 7.1687e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8648e-04 - mae: 0.0143 - mape: 22395.5898 - mse: 3.8648e-04 - val_loss: 8.9682e-04 - val_mae: 0.0209 - val_mape: 4.9900 - val_mse: 8.9682e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9434e-04 - mae: 0.0143 - mape: 15383.3291 - mse: 3.9434e-04 - val_loss: 7.0180e-04 - val_mae: 0.0182 - val_mape: 4.3736 - val_mse: 7.0180e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1054e-04 - mae: 0.0144 - mape: 19373.9531 - mse: 4.1054e-04 - val_loss: 7.3509e-04 - val_mae: 0.0184 - val_mape: 4.4342 - val_mse: 7.3509e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7161e-04 - mae: 0.0141 - mape: 14437.1973 - mse: 3.7161e-04 - val_loss: 7.2536e-04 - val_mae: 0.0182 - val_mape: 4.3886 - val_mse: 7.2536e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7738e-04 - mae: 0.0142 - mape: 13267.1230 - mse: 3.7738e-04 - val_loss: 7.2440e-04 - val_mae: 0.0195 - val_mape: 4.6180 - val_mse: 7.2440e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9052e-04 - mae: 0.0146 - mape: 903.5918 - mse: 3.9052e-04 - val_loss: 6.9608e-04 - val_mae: 0.0188 - val_mape: 4.4720 - val_mse: 6.9608e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6405e-04 - mae: 0.0137 - mape: 6862.3179 - mse: 3.6405e-04 - val_loss: 6.8043e-04 - val_mae: 0.0179 - val_mape: 4.2972 - val_mse: 6.8043e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6137e-04 - mae: 0.0137 - mape: 21244.2832 - mse: 3.6137e-04 - val_loss: 8.4040e-04 - val_mae: 0.0222 - val_mape: 5.1935 - val_mse: 8.4040e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8104e-04 - mae: 0.0143 - mape: 2919.4529 - mse: 3.8104e-04 - val_loss: 6.7156e-04 - val_mae: 0.0178 - val_mape: 4.2693 - val_mse: 6.7156e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9151e-04 - mae: 0.0141 - mape: 5969.4453 - mse: 3.9151e-04 - val_loss: 7.4194e-04 - val_mae: 0.0184 - val_mape: 4.4080 - val_mse: 7.4194e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7576e-04 - mae: 0.0139 - mape: 15714.6816 - mse: 3.7576e-04 - val_loss: 6.5672e-04 - val_mae: 0.0177 - val_mape: 4.2177 - val_mse: 6.5672e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4603e-04 - mae: 0.0137 - mape: 2028.1152 - mse: 3.4603e-04 - val_loss: 6.5951e-04 - val_mae: 0.0175 - val_mape: 4.1941 - val_mse: 6.5951e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6164e-04 - mae: 0.0137 - mape: 4763.3213 - mse: 3.6164e-04 - val_loss: 7.0301e-04 - val_mae: 0.0192 - val_mape: 4.5434 - val_mse: 7.0301e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8424e-04 - mae: 0.0142 - mape: 5645.3584 - mse: 3.8424e-04 - val_loss: 7.4233e-04 - val_mae: 0.0203 - val_mape: 4.7355 - val_mse: 7.4233e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6704e-04 - mae: 0.0140 - mape: 2144.6997 - mse: 3.6704e-04 - val_loss: 6.7399e-04 - val_mae: 0.0186 - val_mape: 4.3760 - val_mse: 6.7399e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0554e-04 - mae: 0.0143 - mape: 1740.5404 - mse: 4.0554e-04 - val_loss: 6.3911e-04 - val_mae: 0.0174 - val_mape: 4.1440 - val_mse: 6.3911e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6208e-04 - mae: 0.0137 - mape: 4651.3975 - mse: 3.6208e-04 - val_loss: 6.8610e-04 - val_mae: 0.0176 - val_mape: 4.2016 - val_mse: 6.8610e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3720e-04 - mae: 0.0131 - mape: 2524.4490 - mse: 3.3720e-04 - val_loss: 6.4042e-04 - val_mae: 0.0171 - val_mape: 4.0747 - val_mse: 6.4042e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2428e-04 - mae: 0.0131 - mape: 7892.2295 - mse: 3.2428e-04 - val_loss: 9.3697e-04 - val_mae: 0.0221 - val_mape: 5.2359 - val_mse: 9.3697e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8029e-04 - mae: 0.0143 - mape: 8569.2441 - mse: 3.8029e-04 - val_loss: 6.5825e-04 - val_mae: 0.0182 - val_mape: 4.2921 - val_mse: 6.5825e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3034e-04 - mae: 0.0132 - mape: 8890.4863 - mse: 3.3034e-04 - val_loss: 6.5817e-04 - val_mae: 0.0172 - val_mape: 4.1016 - val_mse: 6.5817e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4334e-04 - mae: 0.0134 - mape: 4845.9507 - mse: 3.4334e-04 - val_loss: 6.2698e-04 - val_mae: 0.0172 - val_mape: 4.0792 - val_mse: 6.2698e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5360e-04 - mae: 0.0135 - mape: 8417.7988 - mse: 3.5360e-04 - val_loss: 6.2119e-04 - val_mae: 0.0173 - val_mape: 4.0812 - val_mse: 6.2119e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3568e-04 - mae: 0.0133 - mape: 3675.4670 - mse: 3.3568e-04 - val_loss: 6.1562e-04 - val_mae: 0.0167 - val_mape: 3.9756 - val_mse: 6.1562e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.3985e-04 - mae: 0.0133 - mape: 5219.0518 - mse: 3.3985e-04 - val_loss: 6.1151e-04 - val_mae: 0.0171 - val_mape: 4.0306 - val_mse: 6.1151e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2278e-04 - mae: 0.0130 - mape: 15655.5098 - mse: 3.2278e-04 - val_loss: 6.4317e-04 - val_mae: 0.0182 - val_mape: 4.2205 - val_mse: 6.4317e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2566e-04 - mae: 0.0130 - mape: 19992.9961 - mse: 3.2566e-04 - val_loss: 6.0802e-04 - val_mae: 0.0167 - val_mape: 3.9702 - val_mse: 6.0802e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1054e-04 - mae: 0.0128 - mape: 2680.4819 - mse: 3.1054e-04 - val_loss: 6.8829e-04 - val_mae: 0.0177 - val_mape: 4.2119 - val_mse: 6.8829e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6168e-04 - mae: 0.0137 - mape: 260.3518 - mse: 3.6168e-04 - val_loss: 6.4941e-04 - val_mae: 0.0171 - val_mape: 4.0769 - val_mse: 6.4941e-04\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando combinações:  43%|█████████████████████████▎                                 | 3/7 [00:49<01:06, 16.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_1: Processando ação: PETR4, combination: 4...\n",
      "Epoch 1/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0409 - mae: 0.1461 - mape: 7160.4604 - mse: 0.0409 - val_loss: 0.0011 - val_mae: 0.0240 - val_mape: 5.6917 - val_mse: 0.0011\n",
      "Epoch 2/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.9871e-04 - mae: 0.0219 - mape: 867.8113 - mse: 7.9871e-04 - val_loss: 8.2507e-04 - val_mae: 0.0196 - val_mape: 4.7899 - val_mse: 8.2507e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3699e-04 - mae: 0.0171 - mape: 4538.1318 - mse: 5.3699e-04 - val_loss: 7.6372e-04 - val_mae: 0.0185 - val_mape: 4.5607 - val_mse: 7.6372e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8097e-04 - mae: 0.0156 - mape: 603.2739 - mse: 4.8097e-04 - val_loss: 8.7613e-04 - val_mae: 0.0197 - val_mape: 4.8363 - val_mse: 8.7613e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3109e-04 - mae: 0.0149 - mape: 2264.2832 - mse: 4.3109e-04 - val_loss: 7.3619e-04 - val_mae: 0.0184 - val_mape: 4.5109 - val_mse: 7.3619e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3929e-04 - mae: 0.0151 - mape: 11859.5811 - mse: 4.3929e-04 - val_loss: 8.0384e-04 - val_mae: 0.0188 - val_mape: 4.6466 - val_mse: 8.0384e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1273e-04 - mae: 0.0147 - mape: 9649.7393 - mse: 4.1273e-04 - val_loss: 7.1664e-04 - val_mae: 0.0183 - val_mape: 4.4745 - val_mse: 7.1664e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6596e-04 - mae: 0.0154 - mape: 7918.1030 - mse: 4.6596e-04 - val_loss: 7.2419e-04 - val_mae: 0.0188 - val_mape: 4.5688 - val_mse: 7.2419e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3467e-04 - mae: 0.0150 - mape: 7895.9204 - mse: 4.3467e-04 - val_loss: 7.1279e-04 - val_mae: 0.0186 - val_mape: 4.5155 - val_mse: 7.1279e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3283e-04 - mae: 0.0149 - mape: 225.9663 - mse: 4.3283e-04 - val_loss: 7.4800e-04 - val_mae: 0.0183 - val_mape: 4.4910 - val_mse: 7.4800e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1168e-04 - mae: 0.0150 - mape: 6259.5977 - mse: 4.1168e-04 - val_loss: 6.9319e-04 - val_mae: 0.0181 - val_mape: 4.4097 - val_mse: 6.9319e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1044e-04 - mae: 0.0143 - mape: 1518.6779 - mse: 4.1044e-04 - val_loss: 6.9020e-04 - val_mae: 0.0179 - val_mape: 4.3712 - val_mse: 6.9020e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0776e-04 - mae: 0.0144 - mape: 11404.8916 - mse: 4.0776e-04 - val_loss: 6.8284e-04 - val_mae: 0.0177 - val_mape: 4.3261 - val_mse: 6.8284e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9959e-04 - mae: 0.0145 - mape: 1654.8701 - mse: 3.9959e-04 - val_loss: 7.0372e-04 - val_mae: 0.0187 - val_mape: 4.5218 - val_mse: 7.0372e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7073e-04 - mae: 0.0141 - mape: 6003.0576 - mse: 3.7073e-04 - val_loss: 6.7708e-04 - val_mae: 0.0180 - val_mape: 4.3460 - val_mse: 6.7708e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9009e-04 - mae: 0.0143 - mape: 509.2145 - mse: 3.9009e-04 - val_loss: 7.2600e-04 - val_mae: 0.0195 - val_mape: 4.6452 - val_mse: 7.2600e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9411e-04 - mae: 0.0144 - mape: 407.4417 - mse: 3.9411e-04 - val_loss: 6.6998e-04 - val_mae: 0.0177 - val_mape: 4.2959 - val_mse: 6.6998e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9268e-04 - mae: 0.0143 - mape: 1941.3723 - mse: 3.9268e-04 - val_loss: 6.6749e-04 - val_mae: 0.0174 - val_mape: 4.2521 - val_mse: 6.6749e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8986e-04 - mae: 0.0141 - mape: 10353.7695 - mse: 3.8986e-04 - val_loss: 7.3417e-04 - val_mae: 0.0198 - val_mape: 4.7276 - val_mse: 7.3417e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8093e-04 - mae: 0.0140 - mape: 232.2253 - mse: 3.8093e-04 - val_loss: 7.2711e-04 - val_mae: 0.0181 - val_mape: 4.4204 - val_mse: 7.2711e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7611e-04 - mae: 0.0140 - mape: 6340.9951 - mse: 3.7611e-04 - val_loss: 6.4759e-04 - val_mae: 0.0172 - val_mape: 4.1809 - val_mse: 6.4759e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8768e-04 - mae: 0.0142 - mape: 4770.5078 - mse: 3.8768e-04 - val_loss: 6.8012e-04 - val_mae: 0.0174 - val_mape: 4.2536 - val_mse: 6.8012e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9625e-04 - mae: 0.0142 - mape: 3624.4690 - mse: 3.9625e-04 - val_loss: 6.8244e-04 - val_mae: 0.0187 - val_mape: 4.4240 - val_mse: 6.8244e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6981e-04 - mae: 0.0140 - mape: 945.6304 - mse: 3.6981e-04 - val_loss: 6.8662e-04 - val_mae: 0.0188 - val_mape: 4.4463 - val_mse: 6.8662e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6532e-04 - mae: 0.0137 - mape: 5616.6162 - mse: 3.6532e-04 - val_loss: 6.5640e-04 - val_mae: 0.0180 - val_mape: 4.3088 - val_mse: 6.5640e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0324e-04 - mae: 0.0145 - mape: 12796.1582 - mse: 4.0324e-04 - val_loss: 7.0029e-04 - val_mae: 0.0178 - val_mape: 4.3470 - val_mse: 7.0029e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6892e-04 - mae: 0.0141 - mape: 8342.5625 - mse: 3.6892e-04 - val_loss: 6.9031e-04 - val_mae: 0.0190 - val_mape: 4.4908 - val_mse: 6.9031e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9669e-04 - mae: 0.0141 - mape: 926.0962 - mse: 3.9669e-04 - val_loss: 6.8736e-04 - val_mae: 0.0190 - val_mape: 4.4759 - val_mse: 6.8736e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8421e-04 - mae: 0.0142 - mape: 3483.8833 - mse: 3.8421e-04 - val_loss: 6.2457e-04 - val_mae: 0.0171 - val_mape: 4.1125 - val_mse: 6.2457e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2597e-04 - mae: 0.0130 - mape: 19454.4707 - mse: 3.2597e-04 - val_loss: 6.7685e-04 - val_mae: 0.0187 - val_mape: 4.4119 - val_mse: 6.7685e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8602e-04 - mae: 0.0139 - mape: 2679.5374 - mse: 3.8602e-04 - val_loss: 6.3083e-04 - val_mae: 0.0168 - val_mape: 4.0699 - val_mse: 6.3083e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4105e-04 - mae: 0.0132 - mape: 1211.0295 - mse: 3.4105e-04 - val_loss: 6.6897e-04 - val_mae: 0.0173 - val_mape: 4.2158 - val_mse: 6.6897e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9236e-04 - mae: 0.0141 - mape: 2035.7373 - mse: 3.9236e-04 - val_loss: 6.2288e-04 - val_mae: 0.0167 - val_mape: 4.0346 - val_mse: 6.2288e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3154e-04 - mae: 0.0130 - mape: 9700.1826 - mse: 3.3154e-04 - val_loss: 6.1384e-04 - val_mae: 0.0171 - val_mape: 4.0855 - val_mse: 6.1384e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2465e-04 - mae: 0.0132 - mape: 7341.1670 - mse: 3.2465e-04 - val_loss: 6.0781e-04 - val_mae: 0.0166 - val_mape: 4.0014 - val_mse: 6.0781e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5119e-04 - mae: 0.0137 - mape: 3206.8074 - mse: 3.5119e-04 - val_loss: 6.7129e-04 - val_mae: 0.0174 - val_mape: 4.2040 - val_mse: 6.7129e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2698e-04 - mae: 0.0129 - mape: 824.9418 - mse: 3.2698e-04 - val_loss: 6.3116e-04 - val_mae: 0.0178 - val_mape: 4.1952 - val_mse: 6.3116e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6507e-04 - mae: 0.0136 - mape: 2315.0459 - mse: 3.6507e-04 - val_loss: 6.0386e-04 - val_mae: 0.0170 - val_mape: 4.0399 - val_mse: 6.0386e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9049e-04 - mae: 0.0142 - mape: 5596.4189 - mse: 3.9049e-04 - val_loss: 6.1916e-04 - val_mae: 0.0175 - val_mape: 4.1205 - val_mse: 6.1916e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3386e-04 - mae: 0.0131 - mape: 2625.7935 - mse: 3.3386e-04 - val_loss: 6.3069e-04 - val_mae: 0.0178 - val_mape: 4.1960 - val_mse: 6.3069e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6392e-04 - mae: 0.0138 - mape: 357.5330 - mse: 3.6392e-04 - val_loss: 6.2082e-04 - val_mae: 0.0176 - val_mape: 4.1235 - val_mse: 6.2082e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7208e-04 - mae: 0.0137 - mape: 4131.8105 - mse: 3.7208e-04 - val_loss: 5.9335e-04 - val_mae: 0.0168 - val_mape: 3.9901 - val_mse: 5.9335e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2657e-04 - mae: 0.0131 - mape: 5103.4795 - mse: 3.2657e-04 - val_loss: 5.8330e-04 - val_mae: 0.0164 - val_mape: 3.9244 - val_mse: 5.8330e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3774e-04 - mae: 0.0131 - mape: 11972.4561 - mse: 3.3774e-04 - val_loss: 5.9068e-04 - val_mae: 0.0163 - val_mape: 3.9209 - val_mse: 5.9068e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2765e-04 - mae: 0.0128 - mape: 5962.1211 - mse: 3.2765e-04 - val_loss: 6.0259e-04 - val_mae: 0.0164 - val_mape: 3.9753 - val_mse: 6.0259e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4615e-04 - mae: 0.0132 - mape: 5213.9365 - mse: 3.4615e-04 - val_loss: 5.7882e-04 - val_mae: 0.0162 - val_mape: 3.8768 - val_mse: 5.7882e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3787e-04 - mae: 0.0132 - mape: 1182.8528 - mse: 3.3787e-04 - val_loss: 5.8804e-04 - val_mae: 0.0167 - val_mape: 3.9634 - val_mse: 5.8804e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1989e-04 - mae: 0.0130 - mape: 8844.0508 - mse: 3.1989e-04 - val_loss: 5.9924e-04 - val_mae: 0.0172 - val_mape: 4.0337 - val_mse: 5.9924e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9726e-04 - mae: 0.0125 - mape: 11990.9375 - mse: 2.9726e-04 - val_loss: 5.7412e-04 - val_mae: 0.0163 - val_mape: 3.8849 - val_mse: 5.7412e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3652e-04 - mae: 0.0134 - mape: 3046.5603 - mse: 3.3652e-04 - val_loss: 5.9596e-04 - val_mae: 0.0171 - val_mape: 4.0100 - val_mse: 5.9596e-04\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando combinações:  57%|█████████████████████████████████▋                         | 4/7 [01:05<00:49, 16.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_1: Processando ação: PETR4, combination: 5...\n",
      "Epoch 1/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0641 - mae: 0.1904 - mape: 80922.3672 - mse: 0.0641 - val_loss: 0.0115 - val_mae: 0.0901 - val_mape: 18.4405 - val_mse: 0.0115\n",
      "Epoch 2/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0079 - mae: 0.0684 - mape: 739.4866 - mse: 0.0079 - val_loss: 0.0032 - val_mae: 0.0447 - val_mape: 9.9026 - val_mse: 0.0032\n",
      "Epoch 3/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0352 - mape: 7385.0654 - mse: 0.0021 - val_loss: 0.0016 - val_mae: 0.0309 - val_mape: 7.1680 - val_mse: 0.0016\n",
      "Epoch 4/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mae: 0.0241 - mape: 2512.8259 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0241 - val_mape: 5.8398 - val_mse: 0.0011\n",
      "Epoch 5/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0355e-04 - mae: 0.0203 - mape: 8993.6104 - mse: 7.0355e-04 - val_loss: 0.0011 - val_mae: 0.0234 - val_mape: 5.6975 - val_mse: 0.0011\n",
      "Epoch 6/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.2164e-04 - mae: 0.0186 - mape: 3037.9092 - mse: 6.2164e-04 - val_loss: 0.0011 - val_mae: 0.0226 - val_mape: 5.5295 - val_mse: 0.0011\n",
      "Epoch 7/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6273e-04 - mae: 0.0176 - mape: 4669.5806 - mse: 5.6273e-04 - val_loss: 0.0011 - val_mae: 0.0237 - val_mape: 5.7917 - val_mse: 0.0011\n",
      "Epoch 8/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.9770e-04 - mae: 0.0180 - mape: 9937.2988 - mse: 5.9770e-04 - val_loss: 0.0010 - val_mae: 0.0223 - val_mape: 5.4280 - val_mse: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.9672e-04 - mae: 0.0176 - mape: 2541.9189 - mse: 5.9672e-04 - val_loss: 0.0010 - val_mae: 0.0227 - val_mape: 5.5236 - val_mse: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.5741e-04 - mae: 0.0173 - mape: 13351.9951 - mse: 5.5741e-04 - val_loss: 9.8859e-04 - val_mae: 0.0224 - val_mape: 5.4467 - val_mse: 9.8859e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1787e-04 - mae: 0.0167 - mape: 5177.8643 - mse: 5.1787e-04 - val_loss: 0.0010 - val_mae: 0.0216 - val_mape: 5.2875 - val_mse: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0615e-04 - mae: 0.0166 - mape: 5563.8994 - mse: 5.0615e-04 - val_loss: 9.2919e-04 - val_mae: 0.0211 - val_mape: 5.1685 - val_mse: 9.2919e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3671e-04 - mae: 0.0168 - mape: 3038.1948 - mse: 5.3671e-04 - val_loss: 9.2389e-04 - val_mae: 0.0217 - val_mape: 5.2524 - val_mse: 9.2389e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9976e-04 - mae: 0.0160 - mape: 11061.2461 - mse: 4.9976e-04 - val_loss: 8.8861e-04 - val_mae: 0.0208 - val_mape: 5.0682 - val_mse: 8.8861e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.1087e-04 - mae: 0.0162 - mape: 2045.5753 - mse: 5.1087e-04 - val_loss: 9.6519e-04 - val_mae: 0.0209 - val_mape: 5.1317 - val_mse: 9.6519e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6833e-04 - mae: 0.0161 - mape: 4111.0728 - mse: 4.6833e-04 - val_loss: 8.9170e-04 - val_mae: 0.0216 - val_mape: 5.2226 - val_mse: 8.9170e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9707e-04 - mae: 0.0156 - mape: 18860.7207 - mse: 4.9707e-04 - val_loss: 8.3824e-04 - val_mae: 0.0198 - val_mape: 4.8468 - val_mse: 8.3824e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2531e-04 - mae: 0.0149 - mape: 8268.1729 - mse: 4.2531e-04 - val_loss: 8.4073e-04 - val_mae: 0.0196 - val_mape: 4.8099 - val_mse: 8.4073e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3087e-04 - mae: 0.0149 - mape: 2154.2998 - mse: 4.3087e-04 - val_loss: 8.1353e-04 - val_mae: 0.0196 - val_mape: 4.7791 - val_mse: 8.1353e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4285e-04 - mae: 0.0157 - mape: 2020.0911 - mse: 4.4285e-04 - val_loss: 8.1322e-04 - val_mae: 0.0200 - val_mape: 4.8689 - val_mse: 8.1322e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2863e-04 - mae: 0.0149 - mape: 5945.3721 - mse: 4.2863e-04 - val_loss: 7.9047e-04 - val_mae: 0.0192 - val_mape: 4.7001 - val_mse: 7.9047e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1283e-04 - mae: 0.0146 - mape: 8788.9355 - mse: 4.1283e-04 - val_loss: 8.1265e-04 - val_mae: 0.0190 - val_mape: 4.6625 - val_mse: 8.1265e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1442e-04 - mae: 0.0147 - mape: 7291.8638 - mse: 4.1442e-04 - val_loss: 7.6399e-04 - val_mae: 0.0188 - val_mape: 4.5804 - val_mse: 7.6399e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9659e-04 - mae: 0.0142 - mape: 7143.1519 - mse: 3.9659e-04 - val_loss: 7.5784e-04 - val_mae: 0.0188 - val_mape: 4.5817 - val_mse: 7.5784e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0242e-04 - mae: 0.0143 - mape: 845.0839 - mse: 4.0242e-04 - val_loss: 7.5325e-04 - val_mae: 0.0190 - val_mape: 4.6176 - val_mse: 7.5325e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8963e-04 - mae: 0.0144 - mape: 13142.2051 - mse: 3.8963e-04 - val_loss: 7.5298e-04 - val_mae: 0.0184 - val_mape: 4.5086 - val_mse: 7.5298e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7634e-04 - mae: 0.0139 - mape: 2041.4390 - mse: 3.7634e-04 - val_loss: 8.1115e-04 - val_mae: 0.0210 - val_mape: 4.9834 - val_mse: 8.1115e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2526e-04 - mae: 0.0151 - mape: 7492.7451 - mse: 4.2526e-04 - val_loss: 7.2993e-04 - val_mae: 0.0181 - val_mape: 4.4157 - val_mse: 7.2993e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6537e-04 - mae: 0.0140 - mape: 503.9735 - mse: 3.6537e-04 - val_loss: 7.3969e-04 - val_mae: 0.0181 - val_mape: 4.4227 - val_mse: 7.3969e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7035e-04 - mae: 0.0139 - mape: 13839.8242 - mse: 3.7035e-04 - val_loss: 7.2700e-04 - val_mae: 0.0181 - val_mape: 4.4165 - val_mse: 7.2700e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5765e-04 - mae: 0.0138 - mape: 2943.4768 - mse: 3.5765e-04 - val_loss: 8.5443e-04 - val_mae: 0.0222 - val_mape: 5.2728 - val_mse: 8.5443e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8436e-04 - mae: 0.0142 - mape: 356.7901 - mse: 3.8436e-04 - val_loss: 8.1697e-04 - val_mae: 0.0213 - val_mape: 5.0932 - val_mse: 8.1697e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1089e-04 - mae: 0.0143 - mape: 2757.3752 - mse: 4.1089e-04 - val_loss: 7.1052e-04 - val_mae: 0.0178 - val_mape: 4.3557 - val_mse: 7.1052e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4886e-04 - mae: 0.0135 - mape: 4203.5220 - mse: 3.4886e-04 - val_loss: 7.0511e-04 - val_mae: 0.0185 - val_mape: 4.4574 - val_mse: 7.0511e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7400e-04 - mae: 0.0137 - mape: 3366.4739 - mse: 3.7400e-04 - val_loss: 6.8999e-04 - val_mae: 0.0176 - val_mape: 4.2958 - val_mse: 6.8999e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6370e-04 - mae: 0.0139 - mape: 1532.2159 - mse: 3.6370e-04 - val_loss: 6.9069e-04 - val_mae: 0.0179 - val_mape: 4.3504 - val_mse: 6.9069e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7349e-04 - mae: 0.0141 - mape: 624.7548 - mse: 3.7349e-04 - val_loss: 7.3327e-04 - val_mae: 0.0195 - val_mape: 4.6768 - val_mse: 7.3327e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8104e-04 - mae: 0.0142 - mape: 763.8896 - mse: 3.8104e-04 - val_loss: 7.8403e-04 - val_mae: 0.0186 - val_mape: 4.5515 - val_mse: 7.8403e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8398e-04 - mae: 0.0141 - mape: 1165.9160 - mse: 3.8398e-04 - val_loss: 7.9355e-04 - val_mae: 0.0188 - val_mape: 4.5707 - val_mse: 7.9355e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4526e-04 - mae: 0.0134 - mape: 11533.7793 - mse: 3.4526e-04 - val_loss: 7.6131e-04 - val_mae: 0.0184 - val_mape: 4.4842 - val_mse: 7.6131e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8393e-04 - mae: 0.0141 - mape: 3220.0884 - mse: 3.8393e-04 - val_loss: 7.6496e-04 - val_mae: 0.0205 - val_mape: 4.8749 - val_mse: 7.6496e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1438e-04 - mae: 0.0151 - mape: 3632.3455 - mse: 4.1438e-04 - val_loss: 6.9377e-04 - val_mae: 0.0175 - val_mape: 4.2684 - val_mse: 6.9377e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6101e-04 - mae: 0.0136 - mape: 9668.8486 - mse: 3.6101e-04 - val_loss: 6.6983e-04 - val_mae: 0.0177 - val_mape: 4.2809 - val_mse: 6.6983e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7573e-04 - mae: 0.0138 - mape: 1440.9380 - mse: 3.7573e-04 - val_loss: 6.6271e-04 - val_mae: 0.0176 - val_mape: 4.2559 - val_mse: 6.6271e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6757e-04 - mae: 0.0138 - mape: 6384.3848 - mse: 3.6757e-04 - val_loss: 6.6029e-04 - val_mae: 0.0174 - val_mape: 4.2186 - val_mse: 6.6029e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6611e-04 - mae: 0.0137 - mape: 8546.4014 - mse: 3.6611e-04 - val_loss: 6.6736e-04 - val_mae: 0.0172 - val_mape: 4.1915 - val_mse: 6.6736e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4167e-04 - mae: 0.0133 - mape: 1345.5674 - mse: 3.4167e-04 - val_loss: 6.5735e-04 - val_mae: 0.0177 - val_mape: 4.2482 - val_mse: 6.5735e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8908e-04 - mae: 0.0143 - mape: 694.6357 - mse: 3.8908e-04 - val_loss: 6.5531e-04 - val_mae: 0.0173 - val_mape: 4.2036 - val_mse: 6.5531e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4704e-04 - mae: 0.0134 - mape: 1053.7961 - mse: 3.4704e-04 - val_loss: 6.9449e-04 - val_mae: 0.0190 - val_mape: 4.5135 - val_mse: 6.9449e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2166e-04 - mae: 0.0131 - mape: 4327.4351 - mse: 3.2166e-04 - val_loss: 6.6027e-04 - val_mae: 0.0179 - val_mape: 4.2992 - val_mse: 6.6027e-04\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando combinações:  71%|██████████████████████████████████████████▏                | 5/7 [01:22<00:33, 16.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_1: Processando ação: PETR4, combination: 6...\n",
      "Epoch 1/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1347 - mae: 0.2849 - mape: 12099.3730 - mse: 0.1347 - val_loss: 0.0063 - val_mae: 0.0651 - val_mape: 14.4124 - val_mse: 0.0063\n",
      "Epoch 2/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0062 - mae: 0.0610 - mape: 5440.0195 - mse: 0.0062 - val_loss: 0.0026 - val_mae: 0.0390 - val_mape: 9.4216 - val_mse: 0.0026\n",
      "Epoch 3/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mae: 0.0299 - mape: 1697.2064 - mse: 0.0015 - val_loss: 0.0014 - val_mae: 0.0260 - val_mape: 6.4484 - val_mse: 0.0014\n",
      "Epoch 4/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8177e-04 - mae: 0.0216 - mape: 20153.7637 - mse: 7.8177e-04 - val_loss: 0.0012 - val_mae: 0.0234 - val_mape: 5.7926 - val_mse: 0.0012\n",
      "Epoch 5/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.3595e-04 - mae: 0.0190 - mape: 55989.8906 - mse: 6.3595e-04 - val_loss: 0.0012 - val_mae: 0.0225 - val_mape: 5.5801 - val_mse: 0.0012\n",
      "Epoch 6/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.2263e-04 - mae: 0.0184 - mape: 15890.9971 - mse: 6.2263e-04 - val_loss: 0.0011 - val_mae: 0.0223 - val_mape: 5.5004 - val_mse: 0.0011\n",
      "Epoch 7/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.5601e-04 - mae: 0.0176 - mape: 7793.2051 - mse: 5.5601e-04 - val_loss: 0.0011 - val_mae: 0.0222 - val_mape: 5.5092 - val_mse: 0.0011\n",
      "Epoch 8/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.8919e-04 - mae: 0.0177 - mape: 38769.4531 - mse: 5.8919e-04 - val_loss: 0.0011 - val_mae: 0.0216 - val_mape: 5.3428 - val_mse: 0.0011\n",
      "Epoch 9/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6515e-04 - mae: 0.0175 - mape: 49275.3281 - mse: 5.6515e-04 - val_loss: 0.0011 - val_mae: 0.0221 - val_mape: 5.4757 - val_mse: 0.0011\n",
      "Epoch 10/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.7045e-04 - mae: 0.0173 - mape: 61103.8555 - mse: 5.7045e-04 - val_loss: 0.0012 - val_mae: 0.0228 - val_mape: 5.6396 - val_mse: 0.0012\n",
      "Epoch 11/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.3027e-04 - mae: 0.0167 - mape: 2094.0845 - mse: 5.3027e-04 - val_loss: 0.0010 - val_mae: 0.0219 - val_mape: 5.3861 - val_mse: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6494e-04 - mae: 0.0158 - mape: 9054.3086 - mse: 4.6494e-04 - val_loss: 9.9959e-04 - val_mae: 0.0213 - val_mape: 5.2531 - val_mse: 9.9959e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1857e-04 - mae: 0.0166 - mape: 15967.8457 - mse: 5.1857e-04 - val_loss: 9.9800e-04 - val_mae: 0.0211 - val_mape: 5.2353 - val_mse: 9.9800e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.2474e-04 - mae: 0.0164 - mape: 2643.7654 - mse: 5.2474e-04 - val_loss: 9.8634e-04 - val_mae: 0.0209 - val_mape: 5.2036 - val_mse: 9.8634e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9688e-04 - mae: 0.0160 - mape: 8429.3428 - mse: 4.9688e-04 - val_loss: 9.6756e-04 - val_mae: 0.0214 - val_mape: 5.2450 - val_mse: 9.6756e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6083e-04 - mae: 0.0157 - mape: 2618.8286 - mse: 4.6083e-04 - val_loss: 9.6609e-04 - val_mae: 0.0209 - val_mape: 5.1695 - val_mse: 9.6609e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6478e-04 - mae: 0.0155 - mape: 4979.3540 - mse: 4.6478e-04 - val_loss: 0.0010 - val_mae: 0.0214 - val_mape: 5.3086 - val_mse: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0317e-04 - mae: 0.0161 - mape: 2067.9534 - mse: 5.0317e-04 - val_loss: 9.4295e-04 - val_mae: 0.0205 - val_mape: 5.0903 - val_mse: 9.4295e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4895e-04 - mae: 0.0164 - mape: 11788.0205 - mse: 5.4895e-04 - val_loss: 9.3630e-04 - val_mae: 0.0205 - val_mape: 5.0859 - val_mse: 9.3630e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6025e-04 - mae: 0.0153 - mape: 4159.7134 - mse: 4.6025e-04 - val_loss: 9.3697e-04 - val_mae: 0.0205 - val_mape: 5.0863 - val_mse: 9.3697e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0172e-04 - mae: 0.0145 - mape: 481.7442 - mse: 4.0172e-04 - val_loss: 9.5745e-04 - val_mae: 0.0207 - val_mape: 5.1458 - val_mse: 9.5745e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7286e-04 - mae: 0.0153 - mape: 32107.6445 - mse: 4.7286e-04 - val_loss: 8.8470e-04 - val_mae: 0.0204 - val_mape: 5.0069 - val_mse: 8.8470e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3813e-04 - mae: 0.0151 - mape: 7198.8389 - mse: 4.3813e-04 - val_loss: 8.9461e-04 - val_mae: 0.0201 - val_mape: 4.9847 - val_mse: 8.9461e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6069e-04 - mae: 0.0151 - mape: 22924.9746 - mse: 4.6069e-04 - val_loss: 0.0010 - val_mae: 0.0218 - val_mape: 5.4096 - val_mse: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8582e-04 - mae: 0.0161 - mape: 10274.3086 - mse: 4.8582e-04 - val_loss: 8.6149e-04 - val_mae: 0.0198 - val_mape: 4.8895 - val_mse: 8.6149e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8291e-04 - mae: 0.0142 - mape: 17474.7891 - mse: 3.8291e-04 - val_loss: 8.5461e-04 - val_mae: 0.0195 - val_mape: 4.8469 - val_mse: 8.5461e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1468e-04 - mae: 0.0145 - mape: 3791.4854 - mse: 4.1468e-04 - val_loss: 8.4005e-04 - val_mae: 0.0196 - val_mape: 4.8422 - val_mse: 8.4005e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4397e-04 - mae: 0.0152 - mape: 11665.1934 - mse: 4.4397e-04 - val_loss: 8.3189e-04 - val_mae: 0.0196 - val_mape: 4.8170 - val_mse: 8.3189e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4689e-04 - mae: 0.0151 - mape: 1689.5052 - mse: 4.4689e-04 - val_loss: 8.2858e-04 - val_mae: 0.0195 - val_mape: 4.8159 - val_mse: 8.2858e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9054e-04 - mae: 0.0142 - mape: 5125.7715 - mse: 3.9054e-04 - val_loss: 8.2881e-04 - val_mae: 0.0192 - val_mape: 4.7707 - val_mse: 8.2881e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9111e-04 - mae: 0.0141 - mape: 43373.5586 - mse: 3.9111e-04 - val_loss: 8.1559e-04 - val_mae: 0.0198 - val_mape: 4.8420 - val_mse: 8.1559e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.2233e-04 - mae: 0.0145 - mape: 17283.2578 - mse: 4.2233e-04 - val_loss: 8.4116e-04 - val_mae: 0.0193 - val_mape: 4.7838 - val_mse: 8.4116e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1597e-04 - mae: 0.0143 - mape: 3429.5454 - mse: 4.1597e-04 - val_loss: 8.3339e-04 - val_mae: 0.0192 - val_mape: 4.7594 - val_mse: 8.3339e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4571e-04 - mae: 0.0149 - mape: 12854.4375 - mse: 4.4571e-04 - val_loss: 8.5486e-04 - val_mae: 0.0194 - val_mape: 4.8213 - val_mse: 8.5486e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3436e-04 - mae: 0.0148 - mape: 14253.1445 - mse: 4.3436e-04 - val_loss: 9.4637e-04 - val_mae: 0.0207 - val_mape: 5.1392 - val_mse: 9.4637e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1067e-04 - mae: 0.0149 - mape: 4747.7124 - mse: 4.1067e-04 - val_loss: 8.3623e-04 - val_mae: 0.0192 - val_mape: 4.7390 - val_mse: 8.3623e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0484e-04 - mae: 0.0144 - mape: 12393.7510 - mse: 4.0484e-04 - val_loss: 7.8154e-04 - val_mae: 0.0193 - val_mape: 4.7277 - val_mse: 7.8154e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3301e-04 - mae: 0.0147 - mape: 7314.7305 - mse: 4.3301e-04 - val_loss: 7.5826e-04 - val_mae: 0.0186 - val_mape: 4.5658 - val_mse: 7.5826e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7623e-04 - mae: 0.0138 - mape: 4429.2056 - mse: 3.7623e-04 - val_loss: 7.7418e-04 - val_mae: 0.0193 - val_mape: 4.6987 - val_mse: 7.7418e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7053e-04 - mae: 0.0138 - mape: 4597.5586 - mse: 3.7053e-04 - val_loss: 7.5708e-04 - val_mae: 0.0189 - val_mape: 4.6064 - val_mse: 7.5708e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9292e-04 - mae: 0.0140 - mape: 13761.7754 - mse: 3.9292e-04 - val_loss: 8.0615e-04 - val_mae: 0.0205 - val_mape: 4.9141 - val_mse: 8.0615e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2275e-04 - mae: 0.0148 - mape: 6226.5220 - mse: 4.2275e-04 - val_loss: 7.4023e-04 - val_mae: 0.0184 - val_mape: 4.5089 - val_mse: 7.4023e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8301e-04 - mae: 0.0142 - mape: 20873.7031 - mse: 3.8301e-04 - val_loss: 7.3659e-04 - val_mae: 0.0186 - val_mape: 4.5221 - val_mse: 7.3659e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.8166e-04 - mae: 0.0139 - mape: 4938.2080 - mse: 3.8166e-04 - val_loss: 7.2617e-04 - val_mae: 0.0183 - val_mape: 4.4806 - val_mse: 7.2617e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7588e-04 - mae: 0.0140 - mape: 716.1519 - mse: 3.7588e-04 - val_loss: 7.3465e-04 - val_mae: 0.0180 - val_mape: 4.4330 - val_mse: 7.3465e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1256e-04 - mae: 0.0143 - mape: 5739.1885 - mse: 4.1256e-04 - val_loss: 7.4043e-04 - val_mae: 0.0189 - val_mape: 4.5945 - val_mse: 7.4043e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7163e-04 - mae: 0.0141 - mape: 697.2142 - mse: 3.7163e-04 - val_loss: 7.1848e-04 - val_mae: 0.0183 - val_mape: 4.4513 - val_mse: 7.1848e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7624e-04 - mae: 0.0138 - mape: 2127.7844 - mse: 3.7624e-04 - val_loss: 7.2126e-04 - val_mae: 0.0179 - val_mape: 4.3866 - val_mse: 7.2126e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7330e-04 - mae: 0.0140 - mape: 8510.3643 - mse: 3.7330e-04 - val_loss: 7.1372e-04 - val_mae: 0.0181 - val_mape: 4.4171 - val_mse: 7.1372e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8193e-04 - mae: 0.0140 - mape: 4652.8110 - mse: 3.8193e-04 - val_loss: 7.3038e-04 - val_mae: 0.0179 - val_mape: 4.4020 - val_mse: 7.3038e-04\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando combinações:  86%|██████████████████████████████████████████████████▌        | 6/7 [01:39<00:16, 16.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_1: Processando ação: PETR4, combination: 7...\n",
      "Epoch 1/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0711 - mae: 0.2000 - mape: 169890.4375 - mse: 0.0711 - val_loss: 0.0047 - val_mae: 0.0562 - val_mape: 12.6740 - val_mse: 0.0047\n",
      "Epoch 2/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - mae: 0.0478 - mape: 25047.4707 - mse: 0.0040 - val_loss: 0.0016 - val_mae: 0.0290 - val_mape: 7.2537 - val_mse: 0.0016\n",
      "Epoch 3/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mae: 0.0246 - mape: 57138.6523 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0234 - val_mape: 5.8852 - val_mse: 0.0011\n",
      "Epoch 4/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0470e-04 - mae: 0.0195 - mape: 2794.4709 - mse: 7.0470e-04 - val_loss: 0.0011 - val_mae: 0.0233 - val_mape: 5.7322 - val_mse: 0.0011\n",
      "Epoch 5/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9151e-04 - mae: 0.0190 - mape: 19794.3574 - mse: 6.9151e-04 - val_loss: 0.0010 - val_mae: 0.0222 - val_mape: 5.4905 - val_mse: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.8430e-04 - mae: 0.0173 - mape: 5224.9009 - mse: 5.8430e-04 - val_loss: 0.0010 - val_mae: 0.0219 - val_mape: 5.4036 - val_mse: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.4693e-04 - mae: 0.0171 - mape: 4974.2559 - mse: 5.4693e-04 - val_loss: 9.7632e-04 - val_mae: 0.0218 - val_mape: 5.3599 - val_mse: 9.7632e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.9320e-04 - mae: 0.0175 - mape: 27654.6777 - mse: 5.9320e-04 - val_loss: 0.0011 - val_mae: 0.0232 - val_mape: 5.6949 - val_mse: 0.0011\n",
      "Epoch 9/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9543e-04 - mae: 0.0161 - mape: 2292.1599 - mse: 4.9543e-04 - val_loss: 9.3663e-04 - val_mae: 0.0214 - val_mape: 5.2407 - val_mse: 9.3663e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9599e-04 - mae: 0.0166 - mape: 5302.7710 - mse: 4.9599e-04 - val_loss: 9.5913e-04 - val_mae: 0.0212 - val_mape: 5.2105 - val_mse: 9.5913e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.5506e-04 - mae: 0.0170 - mape: 3099.7830 - mse: 5.5506e-04 - val_loss: 9.1150e-04 - val_mae: 0.0208 - val_mape: 5.1086 - val_mse: 9.1150e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7687e-04 - mae: 0.0159 - mape: 10960.7236 - mse: 4.7687e-04 - val_loss: 0.0012 - val_mae: 0.0244 - val_mape: 5.9457 - val_mse: 0.0012\n",
      "Epoch 13/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3442e-04 - mae: 0.0169 - mape: 8595.2100 - mse: 5.3442e-04 - val_loss: 8.8469e-04 - val_mae: 0.0207 - val_mape: 5.0784 - val_mse: 8.8469e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6368e-04 - mae: 0.0155 - mape: 2933.9131 - mse: 4.6368e-04 - val_loss: 8.8507e-04 - val_mae: 0.0203 - val_mape: 4.9924 - val_mse: 8.8507e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8680e-04 - mae: 0.0157 - mape: 2948.9255 - mse: 4.8680e-04 - val_loss: 9.0478e-04 - val_mae: 0.0203 - val_mape: 5.0087 - val_mse: 9.0478e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3260e-04 - mae: 0.0149 - mape: 28433.1055 - mse: 4.3260e-04 - val_loss: 9.9661e-04 - val_mae: 0.0214 - val_mape: 5.2821 - val_mse: 9.9661e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0227e-04 - mae: 0.0161 - mape: 8677.7285 - mse: 5.0227e-04 - val_loss: 8.3710e-04 - val_mae: 0.0201 - val_mape: 4.9087 - val_mse: 8.3710e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4898e-04 - mae: 0.0152 - mape: 14933.5361 - mse: 4.4898e-04 - val_loss: 8.5404e-04 - val_mae: 0.0197 - val_mape: 4.8606 - val_mse: 8.5404e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3982e-04 - mae: 0.0152 - mape: 21440.7051 - mse: 4.3982e-04 - val_loss: 8.1263e-04 - val_mae: 0.0196 - val_mape: 4.7894 - val_mse: 8.1263e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0362e-04 - mae: 0.0145 - mape: 29427.4141 - mse: 4.0362e-04 - val_loss: 8.2010e-04 - val_mae: 0.0202 - val_mape: 4.9160 - val_mse: 8.2010e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5215e-04 - mae: 0.0153 - mape: 13893.2256 - mse: 4.5215e-04 - val_loss: 8.0913e-04 - val_mae: 0.0196 - val_mape: 4.8096 - val_mse: 8.0913e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2552e-04 - mae: 0.0148 - mape: 28268.1738 - mse: 4.2552e-04 - val_loss: 7.9097e-04 - val_mae: 0.0191 - val_mape: 4.6845 - val_mse: 7.9097e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3495e-04 - mae: 0.0149 - mape: 17915.8789 - mse: 4.3495e-04 - val_loss: 7.9679e-04 - val_mae: 0.0188 - val_mape: 4.6400 - val_mse: 7.9679e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3925e-04 - mae: 0.0151 - mape: 9714.9307 - mse: 4.3925e-04 - val_loss: 7.8142e-04 - val_mae: 0.0194 - val_mape: 4.7514 - val_mse: 7.8142e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8856e-04 - mae: 0.0143 - mape: 11352.5771 - mse: 3.8856e-04 - val_loss: 8.5422e-04 - val_mae: 0.0217 - val_mape: 5.1961 - val_mse: 8.5422e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0751e-04 - mae: 0.0161 - mape: 571.7874 - mse: 5.0751e-04 - val_loss: 7.7467e-04 - val_mae: 0.0186 - val_mape: 4.5830 - val_mse: 7.7467e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1011e-04 - mae: 0.0147 - mape: 1232.3931 - mse: 4.1011e-04 - val_loss: 7.5201e-04 - val_mae: 0.0189 - val_mape: 4.6226 - val_mse: 7.5201e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7668e-04 - mae: 0.0137 - mape: 15006.2041 - mse: 3.7668e-04 - val_loss: 7.4416e-04 - val_mae: 0.0186 - val_mape: 4.5522 - val_mse: 7.4416e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1952e-04 - mae: 0.0147 - mape: 624.7702 - mse: 4.1952e-04 - val_loss: 7.7999e-04 - val_mae: 0.0185 - val_mape: 4.5580 - val_mse: 7.7999e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8009e-04 - mae: 0.0141 - mape: 18270.2793 - mse: 3.8009e-04 - val_loss: 8.2003e-04 - val_mae: 0.0213 - val_mape: 5.1107 - val_mse: 8.2003e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2550e-04 - mae: 0.0150 - mape: 8734.9004 - mse: 4.2550e-04 - val_loss: 7.1683e-04 - val_mae: 0.0180 - val_mape: 4.4142 - val_mse: 7.1683e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.6467e-04 - mae: 0.0139 - mape: 18585.3691 - mse: 3.6467e-04 - val_loss: 8.7522e-04 - val_mae: 0.0227 - val_mape: 5.3934 - val_mse: 8.7522e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1444e-04 - mae: 0.0148 - mape: 3618.5383 - mse: 4.1444e-04 - val_loss: 7.1612e-04 - val_mae: 0.0187 - val_mape: 4.5324 - val_mse: 7.1612e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4691e-04 - mae: 0.0134 - mape: 8445.9570 - mse: 3.4691e-04 - val_loss: 7.1137e-04 - val_mae: 0.0178 - val_mape: 4.3699 - val_mse: 7.1137e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9678e-04 - mae: 0.0145 - mape: 1516.2925 - mse: 3.9678e-04 - val_loss: 8.9954e-04 - val_mae: 0.0233 - val_mape: 5.5125 - val_mse: 8.9954e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8694e-04 - mae: 0.0142 - mape: 11161.4805 - mse: 3.8694e-04 - val_loss: 6.8741e-04 - val_mae: 0.0177 - val_mape: 4.3310 - val_mse: 6.8741e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6590e-04 - mae: 0.0133 - mape: 7015.6084 - mse: 3.6590e-04 - val_loss: 7.7911e-04 - val_mae: 0.0186 - val_mape: 4.5787 - val_mse: 7.7911e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6148e-04 - mae: 0.0136 - mape: 19202.7520 - mse: 3.6148e-04 - val_loss: 6.8692e-04 - val_mae: 0.0176 - val_mape: 4.3222 - val_mse: 6.8692e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5857e-04 - mae: 0.0135 - mape: 2866.2043 - mse: 3.5857e-04 - val_loss: 7.1860e-04 - val_mae: 0.0179 - val_mape: 4.3899 - val_mse: 7.1860e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8376e-04 - mae: 0.0139 - mape: 4217.5415 - mse: 3.8376e-04 - val_loss: 8.0432e-04 - val_mae: 0.0214 - val_mape: 5.1255 - val_mse: 8.0432e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4296e-04 - mae: 0.0135 - mape: 9464.2949 - mse: 3.4296e-04 - val_loss: 6.7078e-04 - val_mae: 0.0176 - val_mape: 4.3039 - val_mse: 6.7078e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4944e-04 - mae: 0.0133 - mape: 1205.6688 - mse: 3.4944e-04 - val_loss: 6.8461e-04 - val_mae: 0.0175 - val_mape: 4.2903 - val_mse: 6.8461e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5122e-04 - mae: 0.0137 - mape: 2682.4160 - mse: 3.5122e-04 - val_loss: 7.3327e-04 - val_mae: 0.0180 - val_mape: 4.4304 - val_mse: 7.3327e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8265e-04 - mae: 0.0138 - mape: 4463.6035 - mse: 3.8265e-04 - val_loss: 6.7467e-04 - val_mae: 0.0173 - val_mape: 4.2449 - val_mse: 6.7467e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5108e-04 - mae: 0.0135 - mape: 2615.0383 - mse: 3.5108e-04 - val_loss: 6.8713e-04 - val_mae: 0.0187 - val_mape: 4.5008 - val_mse: 6.8713e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3672e-04 - mae: 0.0135 - mape: 25904.8066 - mse: 3.3672e-04 - val_loss: 6.9928e-04 - val_mae: 0.0176 - val_mape: 4.3154 - val_mse: 6.9928e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4283e-04 - mae: 0.0133 - mape: 22123.3574 - mse: 3.4283e-04 - val_loss: 6.6446e-04 - val_mae: 0.0172 - val_mape: 4.2106 - val_mse: 6.6446e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7849e-04 - mae: 0.0140 - mape: 5919.5156 - mse: 3.7849e-04 - val_loss: 6.6513e-04 - val_mae: 0.0171 - val_mape: 4.1929 - val_mse: 6.6513e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5968e-04 - mae: 0.0138 - mape: 2650.3833 - mse: 3.5968e-04 - val_loss: 8.0095e-04 - val_mae: 0.0218 - val_mape: 5.1077 - val_mse: 8.0095e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8633e-04 - mae: 0.0144 - mape: 4928.3154 - mse: 3.8633e-04 - val_loss: 6.4863e-04 - val_mae: 0.0179 - val_mape: 4.2986 - val_mse: 6.4863e-04\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando combinações: 100%|███████████████████████████████████████████████████████████| 7/7 [01:56<00:00, 16.60s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock</th>\n",
       "      <th>Description</th>\n",
       "      <th>Model</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Val_Loss</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R²</th>\n",
       "      <th>Acurácia</th>\n",
       "      <th>history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PETR4</td>\n",
       "      <td>Stock Data</td>\n",
       "      <td>model_1</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.025225</td>\n",
       "      <td>0.017014</td>\n",
       "      <td>4.061247</td>\n",
       "      <td>0.937021</td>\n",
       "      <td>0.384401</td>\n",
       "      <td>{'loss': [0.0537283830344677, 0.00221196212805...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PETR4</td>\n",
       "      <td>Stock Data + Google News</td>\n",
       "      <td>model_1</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.024964</td>\n",
       "      <td>0.017345</td>\n",
       "      <td>4.100763</td>\n",
       "      <td>0.938319</td>\n",
       "      <td>0.344011</td>\n",
       "      <td>{'loss': [0.03396504744887352, 0.0020460460800...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PETR4</td>\n",
       "      <td>Stock Data + Twitter</td>\n",
       "      <td>model_1</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.024658</td>\n",
       "      <td>0.016720</td>\n",
       "      <td>3.970200</td>\n",
       "      <td>0.939821</td>\n",
       "      <td>0.401114</td>\n",
       "      <td>{'loss': [0.022044915705919266, 0.001054765889...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PETR4</td>\n",
       "      <td>Stock Data + IT (IFR + MMS + MME)</td>\n",
       "      <td>model_1</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.023961</td>\n",
       "      <td>0.016339</td>\n",
       "      <td>3.884865</td>\n",
       "      <td>0.943177</td>\n",
       "      <td>0.410864</td>\n",
       "      <td>{'loss': [0.017256632447242737, 0.000663439219...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PETR4</td>\n",
       "      <td>Google News + Twitter + IFR + MMS</td>\n",
       "      <td>model_1</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.025599</td>\n",
       "      <td>0.017332</td>\n",
       "      <td>4.203560</td>\n",
       "      <td>0.935141</td>\n",
       "      <td>0.385794</td>\n",
       "      <td>{'loss': [0.03331499546766281, 0.0052486308850...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PETR4</td>\n",
       "      <td>Google News + Twitter + IFR + MME</td>\n",
       "      <td>model_1</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.026716</td>\n",
       "      <td>0.018081</td>\n",
       "      <td>4.417148</td>\n",
       "      <td>0.929360</td>\n",
       "      <td>0.369081</td>\n",
       "      <td>{'loss': [0.05916878581047058, 0.0041926926933...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PETR4</td>\n",
       "      <td>Google News + Twitter + IFR + MME + MMS</td>\n",
       "      <td>model_1</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.025468</td>\n",
       "      <td>0.017931</td>\n",
       "      <td>4.298642</td>\n",
       "      <td>0.935802</td>\n",
       "      <td>0.350975</td>\n",
       "      <td>{'loss': [0.034955598413944244, 0.002614361234...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stock                              Description    Model      Loss  \\\n",
       "0  PETR4                               Stock Data  model_1  0.000352   \n",
       "1  PETR4                 Stock Data + Google News  model_1  0.000336   \n",
       "2  PETR4                     Stock Data + Twitter  model_1  0.000355   \n",
       "3  PETR4        Stock Data + IT (IFR + MMS + MME)  model_1  0.000346   \n",
       "4  PETR4        Google News + Twitter + IFR + MMS  model_1  0.000354   \n",
       "5  PETR4        Google News + Twitter + IFR + MME  model_1  0.000368   \n",
       "6  PETR4  Google News + Twitter + IFR + MME + MMS  model_1  0.000355   \n",
       "\n",
       "   Val_Loss       MSE      RMSE       MAE      MAPE        R²  Acurácia  \\\n",
       "0  0.000777  0.000636  0.025225  0.017014  4.061247  0.937021  0.384401   \n",
       "1  0.000667  0.000623  0.024964  0.017345  4.100763  0.938319  0.344011   \n",
       "2  0.000649  0.000608  0.024658  0.016720  3.970200  0.939821  0.401114   \n",
       "3  0.000596  0.000574  0.023961  0.016339  3.884865  0.943177  0.410864   \n",
       "4  0.000660  0.000655  0.025599  0.017332  4.203560  0.935141  0.385794   \n",
       "5  0.000730  0.000714  0.026716  0.018081  4.417148  0.929360  0.369081   \n",
       "6  0.000649  0.000649  0.025468  0.017931  4.298642  0.935802  0.350975   \n",
       "\n",
       "                                             history  \n",
       "0  {'loss': [0.0537283830344677, 0.00221196212805...  \n",
       "1  {'loss': [0.03396504744887352, 0.0020460460800...  \n",
       "2  {'loss': [0.022044915705919266, 0.001054765889...  \n",
       "3  {'loss': [0.017256632447242737, 0.000663439219...  \n",
       "4  {'loss': [0.03331499546766281, 0.0052486308850...  \n",
       "5  {'loss': [0.05916878581047058, 0.0041926926933...  \n",
       "6  {'loss': [0.034955598413944244, 0.002614361234...  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Processando as ações com barra de progresso\n",
    "'''\n",
    "Opções de modelos\n",
    "1: model_1\n",
    "2: model_2\n",
    "3: model_3\n",
    "4: model_linear_simple\n",
    "\n",
    "'''\n",
    "\n",
    "# Lista de ações\n",
    "#stock_list = ['PETR4', 'VALE3', 'BBDC4','ITUB4']\n",
    "stock_list = ['PETR4']\n",
    "\n",
    "# Carregar os dados\n",
    "all_stock_data = load_stocks_data(stock_list)\n",
    "\n",
    "name_model = 'model_1'\n",
    "results_list = []\n",
    "\n",
    "# Usando tqdm para exibir progresso\n",
    "for i in tqdm(range(7), desc=\"Processando combinações\"):\n",
    "    results_list.append(process_stocks_and_save_metrics(stock_list, i + 1, name_model))\n",
    "    #results_list.append(process_stocks_and_save_metrics(stocks, get_stock_data, i + 1, name_model))\n",
    "\n",
    "# Combina os resultados em um único DataFrame\n",
    "results_df = pd.concat(results_list, ignore_index=True)\n",
    "\n",
    "# Exibir o resultado\n",
    "results_df\n",
    "# Salvar em CSV\n",
    "results_df.to_csv(f'Estudos_IEEE_{name_model}.csv', sep=';', encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
