# -*- coding: utf-8 -*-
"""TCC_GoogleNews.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lSUQKYEz5n3pOFRQZwhxSmdITsLYlWhe
"""

import pandas as pd
import datetime
from datetime import datetime

from google.colab import files

!pip list -v | grep dateparser

!pip install -U --no-deps "dateparser>=1.0.0"

"""# Using GoogleNews API"""

# !pip install GoogleNews
# from GoogleNews import GoogleNews
# Google News
#googlenews = GoogleNews(start='01/01/2021',end='01/01/2022')
#googlenews.set_lang('pt')
#googlenews.search('petrobras')

#result = googlenews.result()
#df_gnews = pd.DataFrame(result)

#for i in range(2, 20):
#  googlenews.get_page(i)
#  result = googlenews.result()
#  df_gnews = df_gnews.append(pd.DataFrame(result), ignore_index=True)

#  df_gnews.drop('media',inplace=True, axis=1)
#  df_gnews.drop('datetime',inplace=True, axis=1)
#  df_gnews.drop('desc',inplace=True, axis=1)
#  df_gnews.drop('link',inplace=True, axis=1)
#  df_gnews.drop('img',inplace=True, axis=1)

# df_gnews = df_gnews[['date', 'title']]

# len(df_gnews.index)
# df_gnews.head()

"""# Using PyGoogleNews"""

!pip install pygooglenews --upgrade

!pip uninstall regex -y
!pip install regex==2022.3.2

# PyGoogleNews

from pygooglenews import GoogleNews

# query = string; date_start and date_end = "2020-01-30"
def get_googlenews(savename, query,date_start, date_end):
  gn = GoogleNews(lang='pt')

  #gn_search = gn.search(query, from_=date_start, to_=date_end)

  _news = []

  datelist = pd.date_range(start=date_start, end=date_end, freq='1M').to_list()

  dto = datetime.strptime(date_end, '%Y-%m-%d')
  datelist.append(dto)

  prevdate = date_start

  # begin for
  for date_item in datelist:
    curdate = str(date_item.date())
    gn_search = gn.search(query, from_=prevdate, to_=curdate)

    gb_entries = gn_search['entries']

    # begin for
    for item in gb_entries:
      _date = str(item.published_parsed.tm_year)+"-"+str(item.published_parsed.tm_mon).zfill(2)+"-"+str(item.published_parsed.tm_mday).zfill(2)
      _new = {
          'date':_date,
          'text':item.title
      }
      _news.append(_new)
    # end for
    #
    #
    prevdate = curdate
  # end for
  df_gn = pd.DataFrame(_news)
  df_gn = df_gn.sort_values(by=['date'])

  ffname = "raw_gn_"+savename+"_"+date_start+"_"+date_end+".csv"

  df_gn.to_csv(ffname, sep=',', index=False)

  files.download(ffname)

  return df_gn

start_d = '2008-01-01'
end_d = '2022-09-20'

#get_googlenews('PETR4', 'petrobras OR PETR4', start_d, end_d)
#get_googlenews('ABEV3', 'ambev OR ABEV3', start_d, end_d)
#get_googlenews('BBDC4', 'bradesco OR BBDC4', start_d, end_d)
#get_googlenews('ITUB4', 'itaú OR ITUB4', start_d, end_d)
get_googlenews('VALE3', '"Vale do Rio Doce" OR "VALE3" OR "mineração"', start_d, end_d)

#get_googlenews('VALE3', 'VALE3',      start_d, end_d)
#get_googlenews('vale', '"Vale S.A" OR "Vale empresa" OR "empresa Vale" OR "VALE3" OR "Vale do brasil"',      start_d, end_d)

#get_googlenews('ambev', 'Ambev',     start_d, end_d)
#get_googlenews('itau', 'itau',      start_d, end_d)
#get_googlenews('bradesco', 'Bradesco',  start_d, end_d)

len(dfn.index)

dfn2 = dfn.drop_duplicates(subset=["title"], keep=False)

len(dfn2.index)